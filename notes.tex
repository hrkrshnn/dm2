% Created 2018-11-21 Wed 17:44
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[left=2cm, right=2cm, bottom=2cm, top=2cm]{geometry}
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{amssymb}
\def\R{\mathbb{R}}
\def\Z{\mathbb{Z}}
\def\N{\mathbb{N}}
\def\max{\operatorname{max}}
\def\P{\textup{P}}
\def\NP{\textup{NP}}
\def\coNP{\textup{co-NP}}
\def\min{\operatorname{min}}
\def\dist{\operatorname{dist}}
\def\prev{\operatorname{prev}}
\def\val{\operatorname{val}}
\usepackage[T1]{fontenc}
\author{Hari}
\date{\today}
\title{Discrete Math II}
\hypersetup{
 pdfauthor={Hari},
 pdftitle={Discrete Math II},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.1 (Org mode 9.1.13)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents


\section{Lecture 2\textit{<2018-10-17 Wed>}}
\label{sec:org2ae2521}

\subsection{Review}
\label{sec:org2f3b8d8}
\subsubsection{Random stuff about algorithms}
\label{sec:org2b2236e}
Algorithm A

Input class I

\(T(A, I)\): time algorithm \(A\), input \(I\).

The worst case time complexity of \(A\) on \(I\) is \(\max_{I\in \mathbb{I}} (A, I) = T_(n)\).

The worst case complexity of \(I = \min_{A} T_A(n) = T_{I}(n)\). A function that grows with \(n\).

Average case complexity \(\mathbb{E}(T(A, I))\).
\subsubsection{Sorting}
\label{sec:orga1d5da8}
Sorting algorithm \(A\), \(T(A, \pi) =\) number of comparisons that \(A\) makes to find \$\(\pi\).\$

Yesterday, we proved that for insertion sort (the stupid algorithm), the
worst case running time was \(\binom{n}{2}\).

Binary insertion:  \(T(n) \le n log_2{n}\).

Merges sort: \$T\(_{\text{M}}\)(n) =le n\(\log_{\text{2}}\)\{n\}.\$
\subsubsection{Theorem about lower-bound of sorting}
\label{sec:orgd4c3929}
If \(A\) is a sorting algorithm (correctly sort \(n\) numbers)

Then \(T_A(n) \ge \log_2(n!)\).

In particular, using the stirling's formula, \(T_A(n) \ge n\log_n\).
\begin{enumerate}
\item Proof
\label{sec:org32f87bd}
The algorithm runs on the permutations on the set of \(n\) numbers. Define
\(\forall \kappa \in \N\) blah blah.

\$S\(_{\text{n}}\) \(\subset\) S\(_{\text{n}}\)\{\(\alpha\), \(\kappa\)\} = $\backslash${\(\pi\) \(\in\) S\(_{\text{n}}\) \(\colon\) \textup\{where A
receives input \(\pi\) there, it receives \(\alpha\) as the sequence of the
list of first \(k\) answerers\}$\backslash$}\$
\item Observation
\label{sec:org5e10010}
Everything is determined if we run it.

\(S^n_(\alpha, k) \cap S^n_{\beta, k} = \emptyset \forall \alpha \neq \beta\)

\(\cap S^{n}_{\alpha, k} = S_n\)

Suppose, \(T_A(n) < \log_2(n!)\).

\(S_n = \cap S^n_{\alpha, k}\) partition into \(2^k\) sets.

\(2^k < n!\) implies that there exist \(\beta\) such that there exist \(\pi_1
     \neq \pi_2 \in S_{\beta, r}\).

Run \(A\) on \(\pi_1\), we receive the answers \(\beta\) implies that \(A\) outputs
\(\pi^{*} \in S_n\)

\begin{itemize}
\item Case 1: \(\pi^* \neq \pi_1\), a contradiction to the correctness of \(A\).

\item Case 2: \(\pi = \pi_1\). Run \(A\) on \(\pi_2\) implies \(\beta\) is the answer.
\(A\) outputs \(\pi_{*}\), this is a contradiction that \(\pi_{*} \neq \pi_2\).
Contradicts the correctness of \(A\).

Called the \textbf{information theoretical lower bound}.
\end{itemize}
\end{enumerate}
\subsection{Graph algorithms}
\label{sec:org5771c84}
\subsubsection{Connectedness of graph}
\label{sec:orgffe090c}
A graph \(G\) is connected if for every two vertices \(u\) and \(v\), there exists
a \(uv\) path in \(G\).

This induces an \textbf{equivalence} relation where \(u\) is equivalent to \(v\) if
there exists a path that connects \(u\) and \(v\). Create equivalence classes,
which are called the \textbf{connected components} of \(G\).

Observation: There is no edge between different connected components.
\subsubsection{How do you decide whether a graph is connected?}
\label{sec:orgc24cbc8}
Take a vertex \(v\). We maintain a list of all vertices that are visited. We
redo the same thing for every other vertex. We repeat this until we saw all
the vertices in the graph.

Algorithm (Comp (V))
\begin{verse}
Initialize: Queue Q = v; and W = empty\\
for all \(i \ge 1\)\\
step i: v\(_{\text{i}}\) first vertex in Queue.\\
remove v\(_{\text{i}}\) from the queue  and put it in W\\
put all of \(N(v_i) \setminus W\) into \(Q\).\\
\vspace*{1em}
IF Q = \(\empty\), STOP and return \(W\) as the connected component of \(v\).\\
else go to step i+1\\
\end{verse}
\subsubsection{Theorem: Comp(v) returns \(C_G(v)\)}
\label{sec:org89657ea}
Suppose \(u \in C_G(v) \cap W_{out}\).

Let \(P\) be a vu path in \(G\).

Comp(v) puts a vertex into \(w\) only if all its neighbours are put into \(Q\).
We stop only if \(Q\) is empty. Also \(v_f\) was in \(Q\) at some point \(A\). \(v_f\)
had to be moved to \(w\). This is a contradiction.

Other direction: \(u\in W_{out}\). Before \(u\) became part of \(W\), \(u\) was in
\(Q\). Why? Because there is a \(u_1 \in Q\), \(u \in N(u_1) \setminus W\).
(More things, I skipped.)
\subsubsection{Spanning tree}
\label{sec:org77da5f0}
Suppose we run Comp(v) on a connected graph, where a vertex \(w\) is put into
\(Q\), then there is a unique edge coming with it that attaches it to \(v\).
(the vertex that is moved from \(Q\) to \(W\) at the same time.)
\subsubsection{Theorem about spanning tree}
\label{sec:org5753c1a}
The following are equivalent: for an \(n\) vertex graph.

\begin{enumerate}
\item T is a tree (connected, acyclic.)
\item T is connected and has \(n-1\) edges.
\item T is acyclic and has \(n-1\) edges.
\item For every pair of vertices \(u\) and \(v\) in \(V(T)\), there is a unique \(uv\)
path.
\end{enumerate}
\begin{enumerate}
\item Definition (spanning tree)
\label{sec:org6c0121d}
\(T \subset G\) is a spanning tree if \(T\) is a tree and \(V(T) = V(G)\).
\end{enumerate}
\subsubsection{Special spanning trees}
\label{sec:org37c7eb3}
Let \(G\) be connected and run Comp(v) (don't forget the edges.)

\emph{What if} we always put \(N(v_i) \setminus W\) to the top of \(Q\). (We call
this the \textbf{depth first search} tree.) This is going to create a tree which is
long (?)

\emph{What if} if we put it to the bottom of the tree, this will create a
\textbf{breadth first search}. You will create which is short.

A diagram that I ignored.
\subsection{Minimal spanning tree}
\label{sec:orge7aede6}
Given a graph \(G\). (can be a complete or arbitrary graph.)

We have a weight function that is assumed on the edge set to \(\mathbb{R}\).
What we want is a spanning tree \(T\subset G\) such that the cost of the sum of
weights on the edges is minimum (i.e., for any other spanning tree, the sum
of the weights on the edges would be more than the current one.)
\subsubsection{Naive algorithm}
\label{sec:org6136414}
There is at most \(n^{n-2}\) (Cayley's theorem.) spanning trees on \(n\) vertices. Let's look at all
of them and calculate the weights and output the minimum.
\subsubsection{Kruskal's algorithm}
\label{sec:org40c0aa1}
\begin{enumerate}
\item Step 1
\label{sec:org75cafc2}
Sort edges in increasing order of weights \(e_1, \cdots e_m\) such that
\(w(e_1) \le w(e_n) \le \cdots, \le w(e_n)\).

Start with an empty forest \(E(F) \neq \emptyset\) for all \(v \in V\), \(c_v = v\).
\item Step 2
\label{sec:org731d169}
For each edge \(e_i = uv\). For \(\forall i \ge 1\), if the forest plus the new
edge has a cycle, then \(C_v\) remains the same.

If there is no cycle, we have a new forest, i.e., the bigger forest with
the extra edge added to it.
\item The end
\label{sec:org4326bd2}
Output \(F\).
\end{enumerate}
\subsubsection{Theorem: Kruskal's algorithm returns the min-weight spanning tree.}
\label{sec:orgadf2b08}
Proved in discrete Math 1. 
\subsubsection{Running time of Kruskal}
\label{sec:org169db3f}
The first step involves sorting. This can be done in \(O(|E| \log|E|)\).

There is \(O(m)\) and \(O(n^2)\). 

If \(G\) is dense, then \(O(m\log m)\) and if \(G\) is sparse, then \(O(n^2)\).
\section{Lecture 3 \textit{<2018-10-23 Tue>}}
\label{sec:orgace9ae8}
\subsection{Spanning trees}
\label{sec:org7f52074}
Another perspective: get to one place to another in the fastest way possible.
Versus the minimum spanning tree. \footnote{MST would be city-side and the fastest possible way would be consumer side.}
\subsection{Problem}
\label{sec:orgc027c40}
Given graph \(G=(V, E)\), a distance for \(d\colon E \rightarrow \mathbb{R}_{\ge 0}\). 

\textbf{Goal}: Given a vertex \(u\in V\), find the shortest path to any vertex \(v \in V\). 

The brute force way is to find all the path and find the minimu. 
\subsection{Idea}
\label{sec:orgc9ba399}
Maintain a set of vertices to where a shortest path from \(u\) was found. And
in each step we add one vertex to \(W\).

\textbf{Key observation}: If \(P\) is a shortest \(uv\) path, then for every \(w\) on this
 path, \(P[u, w]\), this is also the shortest path. (\(P[u, w]\) represents the
 path from \(u\) to \(w\) through \(P\).)
\subsection{Dijkstra's algorithm}
\label{sec:org2c3d3a8}
\textbf{Input} is a graph \(G = (V, E)\) which is connected. \footnote{Otherwise you can explore the components.} We have a distance
\(d\colon E \rightarrow \mathbb{R}_{\ge 0}\).

\textbf{Output}: For every vertex \(u \in V\), the distance from \(u\) and also a
shortest path.
\subsubsection{Algorithm}
\label{sec:orgcc487d2}
\textbf{Initialization}: dist[u] = 0

For every other vertex \(v\), I set \(d[v] = \infty\). \(prev[v] =
    \textup{null}\). Maintain the set \(W = \emptyset\). 

\textbf{Iteration}: Choose a vertex \(v_0 = \min\{\dist[v]\colon v  \in V \setminus W\}\)

Update \(W = W \cap \{v_0\}\).

\(\forall v \in V \setminus W\) if \(\dist[v] > \dist[v_0] + d(v_0, v)\)
then \(\dist[v] = \dist[v_0] + d(v_0, v)\) and \(\prev[v] = v_0\). 

\textbf{Termination}: If \(W = V\), then STOP and output \(\dist[v]\) search head of
\(\prev\) for a \(uv\) path.

An example was done. \href{https://en.wikipedia.org/wiki/Dijkstra\%27s\_algorithm}{Wikipedia}. 
\subsubsection{Analysis}
\label{sec:orgd06a849}
\begin{enumerate}
\item Correctness
\label{sec:orgb5ff014}
\textbf{Claim}: At the time \(v_0\) is put into \(W\), \(\dist[v_0]\) is the distance of
 \(v_0\) to \(u\). 

(This would prove the correctness, because \(dist\) does not change after
vertex is in \(W\).)

Proof: Induction on \(\vert W\vert\).

Because \(\vert w \vert = 0\) \(u\) is put into \(W\), \(\dist[u] = 0 = d(uu)\). 

Suppose \(\vert W \vert \ge 1\), we put \(v_0\) into \(W\). If this is the case,
then \(\dist[v_0] = \min\{\dist[v_0]\colon v \in V \setminus W\}\).

Suppose \(\dist[v_0] > s(uv_0)\). (here \(s\) is the shortest path going
from one vertex to another.)

Take the shortest \(uv_0\) path \(P\). There will be a first vertex on \(P\) not
in \(W\), call it \(v_f\) and \(v_p\) be its predecessor. \(\dist[v_0] > s(uv_0)
      = s(uv_f) + s(v_fv_0) \ge s(uv_f) = s(uv_p) + s(v_pv_f) = dist[v_p] +
      d(v_pv_f)\). (By our observation from before, both these paths are the
shortest.)

When we are updating after putting \(v_p\) into \(W\), we consider \(v_f\) and
we will put it in \(W\). This is a contradiction. 
\item Termination
\label{sec:org0c4369a}
In each iterating step, one vertex is put into \(W\) and stays there and then
in \(n\) iterations, we are done. 
\item Cost
\label{sec:org0089c20}
Finding \(v_0\), then \(O(\vert V \vert)\).

Adding \(v_0\) to \(W\) is \(O(1)\)

Updating \(\dist\),  \(O(\vert V\vert)\).

With better data structure \(O(\vert E\vert + \vert V \vert log \vert V \vert)\).
\end{enumerate}
\subsection{Euro 2020 or Travelling Salesman Problem}
\label{sec:orgf1ee21f}
Watch a game in every one of \(13\) cities. We want to visit all \(13\) but as
cheap as possible. The English football fans cannot return to the same
country. A \(13\) vertex graph, between any two vertices, there is a price of
the air ticket.

We are looking for a Hamilton cycle.

Given graph \(G = (V, E)\) and \(w\colon E \rightarrow \R_{\ge 0}\). A cycle
that does not repeat.
\subsection{Complexity classes}
\label{sec:org0c05ed3}
\(\P\), polynomial time running problem. 

\begin{center}
\begin{tabular}{rlllll}
\(n\) & \(1000n\) & \(1000n\log n\) & \(10n^2\) & \(2^n\) & \(n!\)\\
\hline
10 & 0.01 sec & 0.0002 sec & 0.001 & 0.0000001 sec & 0.003 sec\\
100 & 0.1 sec & 0.001 sec & 000001 sec & 400000 years & \(>10^100\) years\\
100000 & 17 min & 20 sec & 2450 min & \(>10^100\) years & \\
\end{tabular}
\end{center}
\section{Lecture 4 \textit{<2018-10-24 Wed>}}
\label{sec:org5713093}
\subsection{Decision problems}
\label{sec:orgb7bb7e5}
Problems that output yes or no
\subsubsection{Example}
\label{sec:orgac6e8c0}
\begin{itemize}
\item Is there a spanning tree of weight \(\le 42\). (Kruskal algorithm.)
\item Is there a path of weight \(\le 405\) from \(u\) to \(v\)? (Djistra's algorithm.)
\end{itemize}
\subsection{Class P}
\label{sec:orge78124e}
The set of all decision problems with a polynomial time algorithm. 
\subsection{Traveling salesman problem}
\label{sec:orgc0b426a}
We don't know if the problem is in \(\P\). 

As a decision problem: There is a graph \(G = (V, E)\) and \(w\colon E
   \rightarrow \R_{\ge 0}\)., You ask what is the smallest weight Hamiltonian cycle. \footnote{"and the decision problem version ("given the costs and a number x, decide
whether there is a round-trip route cheaper than x") is NP-complete."-Wikipedia}
\subsubsection{Approximation algorithm}
\label{sec:org8d3a1fe}
\textbf{Definition}: An \(\alpha\) approximation of TSP is an algorithm that turns a
 Hamiltonian cycle whose weight is within \(\alpha\) fraction of the min
 weight Hamiltonian cycle.\footnote{In general we don't know how to approximate the TSP, but we can do it with some extra conditions}
\subsubsection{Extra conditions}
\label{sec:orgcdeaa63}
Triangle inequality: the weight function satisfies the triangle inequality
if every two vertices of the graph, the weight \(w(xy) \le w(xz) + w(zy)\).

Examples: The usual Euclidean distance satisfies this. 
A non-example is Airfare cost.
\subsection{Approximation algorithm for TSP}
\label{sec:orgae054ce}
\subsubsection{Algorithm}
\label{sec:org42057c6}
\textbf{Input}: a weight function \(w\colon E(K_n) \rightarrow \R_{\ge 0}\) with
triangle inequality. (We assume that it is a complete graph.)

\textbf{Output}: Hamiltonian cycle \(C\).

\textbf{Algorithm}:
\begin{enumerate}
\item Find the minimum weight spanning tree (Kruskal algorithm.)
\item From the spanning tree, we create a closed walk spanning all vertices by
traversing each edge of \(T\) twice in both directions.
\item Traverse \(W\), when hitting a vertex that was used before, we do a short
cut. (Go instead to next vertex \(W\)) Do this iteratively.
\end{enumerate}
4 \textbf{Termination}: when all vertices are traversed, output \(C\). 

We know that \(w(W) = 2w(T)\) and \(w(C) \ge w(W)\). 

\(C^{*}\) is a minimum weight Hamilton cycle. How does this compare to the
weight of the spanning tree. We know that \(w(C^{*}) \ge w(T)\). and thus
\(w(C) \le 2 w(C^{*})\).
\subsubsection{Running time}
\label{sec:orgfadd199}
\begin{enumerate}
\item Kruskal: \(O(n^2\log n)\)
\item Closed walk \(W\), \(O(n)\).
\item short cutting: \(O(n)\).
\end{enumerate}
\subsection{Hall's theorem}
\label{sec:org4e778b2}
If \(G = (A \cap B, E)\) a bipartite graph, then \(G\) has a matching \(A\) if and
only if for every subset \(S \subset A\), \(\vert N(S) \vert \ge \vert S \vert\).

The non-trivial direction implies that when there is no matching saturating
\(A\), then there is an \(S \subset A\), \(\vert N(S) \vert < \vert S \vert\).
\subsection{Class \(\NP\)}
\label{sec:orgb189489}
A decision problem is in class \(\NP\) if the YES answer can be verified
efficiently (within time that is polynomial in variable size.) (In other
words, there is a polynomial size certificate.)

The perfect matching problem is in NP. \footnote{Input is a graph \(G\) and the question is whether there is a perfect matching.}

Opposite of perfect matching: Does \(G\) has a \(PM\)? We can use Hall's
condition as a certificate. Hence the problem is in NP.
\subsection{Class \(\coNP\)}
\label{sec:orge390122}
Means that the problem is in \(NP\) and the negation of the problem is also in
\(NP\).
\subsection{About Hamilton path}
\label{sec:orgc31c153}
The Hamilton path problem is in \(NP\). 

But the negation of the HAM is not known to be in \(NP\). In other words, we
don't know if HAM is \(\coNP\).\footnote{The belief is that this is not true. This is one of the Millennium problems.}
\subsection{Problem reduction}
\label{sec:orgdff83fe}
Maximum weight spanning tree problem can be reduced to a minimum weight
spanning tree. (You can solve the minimum weight spanning tree problem by
inverting the sign of the edges.) Furthermore, it is a polynomial time
reduction.

A problem is called \(\NP\) hard if any problem in \(\NP\) class can be reduced
by the problem.

If furthermore, the problem is in \(\NP\), then we call it \(\NP\) complete.

Example: 3-SAT is \(\NP\) hard and also \(\NP\) complete. 

Karp came up with \(21\) natural \(\NP\) complete problems, all of them are \(\NP\)
complete.
\section{Lecture 5 \textit{<2018-10-30 Tue>}}
\label{sec:orgc7f05f4}
\subsection{NP class}
\label{sec:org66ea83e}
A yes/no problem is in class NP if the answer yes can be verified
efficiently.
\subsubsection{Examples}
\label{sec:org3329fa7}
\begin{enumerate}
\item Does the bipartite graph have a perfect matching.
\item Does the bipartite graph have no perfect matching.
\item Does the graph have a Hamiltonian-cycle?
\item \textbf{Don't know} Whether a problem have no hamiltonian cycle.
\end{enumerate}
\subsection{P class}
\label{sec:org990a000}
A yes/no decision problem is in P if the answer can be found in polynomial
time. It is obviously true that \(P \subset NP\).
\subsection{Co-NP}
\label{sec:org4fa0902}
A yes/no problem is in the class Co-NP if the no-answer can be verified
efficiently. Again trivially, \(P \subset NP \cap no-NP\).
\subsubsection{Example of NP intersection co-NP}
\label{sec:org5df7315}
\begin{enumerate}
\item Perfect matching problem in bipartite graph is in the intersection.
\item Is this graph 2-colorable.
\item Is this graph Eulerian?\footnote{I think it's about going through each edge once.} Verify that the degree of each vertex is even.
(polynomial time algorithm.) Another answer: The yes answer is the list
of edges in an Eulerian edges. For the NO answer, we will be given a
vertex of odd-degree.
\end{enumerate}
\subsection{Conjecture P \(\neq\) NP}
\label{sec:orgcfb37a7}
\subsection{Stronger conjecture of \(P \neq\) \(NP\) intersection \(co-NP\)}
\label{sec:org58a9f8b}
Is there a factor of \(n < k\). This problem is in the intersection of NP and
co-NP.

Is \(n\) a prime. This was also a problem. But in 2002, it was proven to be
true. (The input size is in \(\log n\).)

A problem in \(NP\) and co-NP and then trying to find a good characterization
and then solving the problem.
\subsection{NP completeness}
\label{sec:org6aaa350}
Subtle difference between easy and hard problem.
\begin{enumerate}
\item The graph is 2-colorable? is in P\footnote{Apparently there is a characterization that a graph is 2 colorable if and
only if it has no cycle.}
\item Is the graph 3-colorable? is in NP-complete.
\item Is this planar graph 3-colorable? is in NP-complete.
\item Is this planar graph 4-colorable? is in P. (The is in complexity class TRIVIAL)
The answer is always yes.
\end{enumerate}
\subsection{Hall's theorem}
\label{sec:orgb663b9c}
If you have a graph \(G\) that is bipartite, then \(G\) has a perfect matching if
and only if for every \(S\) inside \(A\), the \(\vert N(S) \vert \ge \vert S
   \vert\) and for every \(S \subset B\).
\subsection{Necessary conditions for Hamiltonianity}
\label{sec:orgeadf97c}
Dirac's theorem \(d(G) \ge n/2 \implies G\) is hamiltonian. \href{https://en.wikipedia.org/wiki/Hamiltonian\_path\#Bondy\%E2\%80\%93Chv\%C3\%A1tal\_theorem}{Wikipedia} (This is
a sufficient condition.) For a cycle, this fails.   

Proposition: If a graph \(G\) is hamiltonian then \(\forall S \subset V(G)\),
\(C(G\setminus S) \subset \vert S \vert\). (This is a necessary condition.)\footnote{Here \(C\) is the number of connected components in the graph.} \textsuperscript{,}\,\footnote{Peterson graphs can be used to make a lot of counter examples. This was
taught in discrete math 1.}

A simple example is an edge. It's probably also true for Peterson graph.

We can try to frame something like if \(t C(G\setminus S) \subset \vert S
   \vert\). For peterson graph \(t = 4/3\). There is a conjecture on if we can talk
about a value of \(t\) and do stuff.
\subsection{Does a graph have a perfect matching? Tutte's theorem}
\label{sec:orgc05fd4c}
The question is whether this is in NP intersection co-NP. 

The hall's theorem was for bipartite graph.

Consider \(K_{2k+1}\). It has all the edges, but has no perfect matching. Odd
(vertices) graphs are bad obviously.

There was something about applying the necessary condition for Hamiltonian
cycle to the matching problem and arriving at a necessary condition (and sufficient condition.)

\(G\) has a perfect matching \(\implies\) \(\forall S \subset V(S)\), \(o(G
   \setminus S) \subset |S|\).\footnote{Here \(o\) is the number of components of odd size.}

\textbf{Proof}: Let \(M\) be a perfect matching in \(G\). In each odd component, there
is at least one edge \(e_L \in M\) which has one vertex in \(b\) and the other in
\(S\). These edge \(e_L\) are disjoint \(\implies\) \footnote{My condition} \textsuperscript{,}\,\footnote{\href{https://en.wikipedia.org/wiki/Tutte\_theorem}{Tutte's theorem}}
\subsection{Proof of Tutte's theorem}
\label{sec:orgbf5b760}
Let \(G\) be a counter example with maximum number of edges.\footnote{Why can we do this? We fix the number of vertices, so this it actually
makes sense.}

What is a counter example? It should satisfy the following properties:
\begin{enumerate}
\item \(G\) has no perfect matching
\item \(\forall S \subset V(G)\), \(o(G \setminus S) \le \vert S \vert\)
\end{enumerate}

Add \(xy\) to \(G\) and \(G+xy\) is not a counter example. We claim that \(\forall S
   \subset V(G)\), \(o((G+xy)\setminus S) \le \vert S \vert\). \footnote{Here \(xy\) is an edge that is not already in \(G\).}

I know that \(o(G\setminus S) \le \vert S \vert\).
\begin{itemize}
\item If \(xy \in S = \emptyset \implies \vert S \vert\) does not decrease.
\item If \(xy\) goes between even components, then nothing changes.
\item If \(xy\) goes to an odd components, the number of odd components decreases.
Basically do a case analysis and it checks out.
\end{itemize}

\(U = \{v \in V(G) \colon d(v) = n- 1\}\)

Case 1. \(G \setminus U\) is the disjoint union of cliques. There are even
cliques and odd cliques. Even cliques can be matching within themselves. In
odd cliques, you match everything but one, but we can match the extra vertex
to \(U\). Now what happens with the vertices inside \(U\) that doesn't get a pair
in \(U\). If that part is odd, then the whole thing is not odd. But it is not
odd, because we have a contradiction when we put \(S = \emptyset\). So after
everything, the number of unmatched vertices is even (otherwise we have a
contradiction.)

Case 2. \(G \setminus U\) is not a disjoint union of cliques. The idea is from
two almost perfect matching of \(G\), create a perfect matching of \(G\) and two
more edges, create a perfect matching. This leads to a contradiction. 

Claim: In \(G, \exists x, u, v, w\) such that \(xu, xv, \in E\), \(uv, vw \notin
   V(G)\). \(w\) is anything that is not in the neighbourhod of \(x\) which is non
empty.\footnote{I think I missed some parts to the explanation.}

\begin{verbatim}

                   x .--------------------------- w
                    /.
                   /  -\                           
                 -/     \                          
                /        -\                        
               /           -\                      
             -/              \                     
            /                 -\                   
           /                    \                  
          /                      -\                
        -/                         \               
       /                            -\             
      /                               -\           
    -/                                  \          
   /                                     -\        
u .----------------------------------------. v


\end{verbatim}
\section{Lecture 6 \textit{<2018-10-31 Wed>}}
\label{sec:org3144b66}
\subsection{{\bfseries\sffamily TODO} Tutte's theorem proof}
\label{sec:org5c5c685}
\(\Leftarrow\): G\$, a counter example with maximum number of edges.

\textbf{Claim}: \(G+xy\) has a p.m. \(xy\in E(G)\), \(G\) has no p.m., \(\forall S \in
    V(G)\), \(o(G \setminus S) \le o(\vert S \vert)\)

\(U = \{v \colon deg(v) = n-1\}\) and \(n=\vert V(G)\vert\).

Case 1: \(G \setminus U\) is the union of cliques. We are done, we use Tutte's
condition for empty set. 

Case 2: Otherwise, there exists the diagram that I already drew. Our claim
implies that there exists a perfect matching \(M_1\) in \(G + xw\) and also
there is a perfect matching in \(G\) if one adds \(uv\). Our goal is to find a
perfect matching in \(M_1 \cap M_2\). Our goal is to find a perfect matching
in \(M_1 \cap M_2 \setminus \{xw, uv\} \cap \{ux, xv\} \subset E(G)\).

\(M_1 \cap M_2\) is the disjoint union of \$K\(_{\text{2}}\)\$s and even cycles\footnote{Is the \(K_2\) here an edge?}. The degree
of each vertex in the union is either \(1\) or \(2\), because the matching is
perfect because there are two of them. If there is one, then the vertex
participates in the same edge with () matching \(\implies\) \(K_2\) component.

If it is \(2\) \(\implies\) vertex participates in a cycle component.

(cycle is even since edges of the matchings alternate.)

There was a diagram and the proof involved doing stuff on the diagrams. I
don't understand what he did.

The proof in the class was from bondy and murthy. \href{http://www.zib.de/groetschel/teaching/WS1314/BondyMurtyGTWA.pdf}{Bondy and murthy} page 76. 

The wikipedia link seems to have the same proof.
\subsection{Perfect matching is in NP intersection co-NP}
\label{sec:org167a67f}
Tutte's theorem tells us that the problem is in the intersection of NP and
co-NP. The certificate for the yes case is a matching and for the No case is
a case where the Tutte's theorem is false.

The problem is also in P.
\subsection{Corollary to hall theorem (Theorem of Frobenius)}
\label{sec:org28b1e4a}
A \(k\) regular bipartite graph has perfect matching.\footnote{What is regular graph? Every vertex has the same number of neighbours.} (1-factor)

A \(k\) factor is a spanning \(k\) regular subgraph. 

This is not true for general graphs. Example: odd cycles, they are \(2\)
regular and 1-factor. Are there examples with even number of vertices.
(3-regular graph with no \(1\) factor.)


\subsection{Theorem (peterson)}
\label{sec:org809db7c}
A \(2k\) regular subgraph has a \(2\) factor. 
\subsection{Theorem (another peterson theorem)}
\label{sec:orgb947f20}
Every \(3\) regular graph without cut edges\footnote{What is a cut edge? A cut edge should mean that you remove an edge and
the graph gets disconnected.} has a perfect matching. (Theorem in
Bondy and Murthy) \footnote{An example of such a graph is Peterson graph.}
\subsubsection{Proof}
\label{sec:org019d2ce}
The proof is component wise. Now we assume that \(G\) is connected.

We will check that Tutte's condition holds. Then Tutte's theorem tells us
that \(G\) has a perfect matching.

\(S\) be an arbitrary subset.

Consider the number of edges between odd components and \(S\).

Claim: For every odd component, there is at least three edges going to \(S\)
from \(C\).

Proof:
\begin{enumerate}
\item \(0\) edges is not possible because connected.
\item \(1\) edge is
not possible, because it would be a cut edge.
\item \(2\) edges are not possible
because the sum of the degrees of the vertices inside the component -2,
\(\sum d(v) - 2 = 2 \cdot e(C)\). Now this is just a handshake lemma.\footnote{What is a handshake lemma?}
\end{enumerate}

The number of edges between odd components and \(S\). The number of edges
going is at least \(3\) times the odd components. On the other hand, the
number of components cannot be more than \(3 \vert S \vert\).

$$ 3\cdot o(G \setminus S) \le \textup{number of edges between odd components and S } \le 3 \cdot \vert S \vert$$

Thus \(\cdot o(G \setminus S) \le \vert S \vert\)
\subsection{Maximum matching problem}
\label{sec:org6588e47}
In the decision problem formulation. Is there a matching of size \(k\) in the
graph on \(n\) vertices.

Is this problem in NP intersection co-NP? The problem is obviously in NP. 

For Bipartite graphs, we can provide the other verification by Konig's
theorem.
\subsection{Konig's theorem}
\label{sec:orgac34864}
\(G\) is bipartite, then \(\alpha(G)=\beta(G)\). Here \(\alpha\) is the size of the
largest matching and \(\beta\) is the size of smallest vertex cover.

\(C \subset V(G)\), the vertex cover if \(\forall e \in E(G)\), \(e\cap C \neq
   \emptyset\).
\subsection{Konigs on Maximal matching problem}
\label{sec:org9e66da2}
Suppose \(\alpha(G) = 88\), then konig gives a certificate to show that there
exists a vertex cover of size \(88\). So this means that there are no matching
of size more than \(89\).
\subsection{Homework: a corollary of Tutt due to Berge}
\label{sec:orga99db3f}
If \(G\) is a arbitrary graph, then it is true that \(2\alpha'(G)\) is equal to
the minimum of the following sum of quantities: \(\min \{ n - o(G\setminus
   S) + \vert S \vert \colon S \subset V(G) \}\).\footnote{If the graph satisfies tutt's condition, then \(\alpha\) should evaluate
to \(n/2\).}

It is easy to show one direction. But this is the maximum size, which is the homework.

This example would put the problem of maximum matching into the intersection.
\subsection{How to find maximum matchings in polynomial time?}
\label{sec:org50cd07c}
\subsection{Proposition about maximum matching}
\label{sec:org1cbca5e}
IF \(M \subset E(G)\) is a maximum matching of \(G\), \(\iff\) there is no
\(M\) augmenting path.

\(M\) augmenting path: It's a path in which non-edges and edges follow each
other alternatively. One direction is easy. If \(M\) is a maximum matching,
then there is no \(M\) augmenting path.
\subsection{A M alternating path}
\label{sec:orgf48d6b5}
A path of \(G\) where edges of \(M\) alternate with non-edges of \(m\).

An \(M\) alternating path that starts and ends in an unsaturated vertex is
called \(M\) augmenting. \href{https://en.wikipedia.org/wiki/Saturation\_(graph\_theory)}{Wikipedia}
\subsection{Using the characterization for Bipartite graph}
\label{sec:org352d5a8}
\footnote{Apparently the problem for general graph is also in P. The algorithm for
this graph was what lead to the definition of \(P\).} You have a matchin and then unsaturated vertices. The idea is to
somehow extend the matching to the unsaturated edges.

\begin{verbatim}
-------------------------------------------------------------\------------------------------\---------------
-                                                                                                           \------
(                                                                                                                  )
\              |           |              |              .                                                  /------
\              |           |              |                            .                    /---------------
\              |           |              |                  /------------------------------
---------------------------+--------------+------------------
                |          |              |
                |           \              \
                |           |              |
                 \          |            --+----------------------------------------------------------------------------------------------------------------------
       ----------+----------+-----------/  |                                                                                                                      \---------------------------------
------/          |          |             .|                 .           .     .       .                                                                                                            \------------
(                           |                                                                                                                                                                                    )
------\                                                                                                                                                                                             /------------
       ---------------------------------\                                                                                                                         /---------------------------------
                                         -------------------------------------------------------------------------------------------------------------------------



\end{verbatim}
\section{Lecture 7 \textit{<2018-11-06 Tue>}}
\label{sec:org26d0d0f}
\subsection{Maximum matching is in P}
\label{sec:org20217a2}
\subsubsection{Proposition}
\label{sec:org0e72099}
\(M \subset E(G)\) is a matching in \(G\).

\(M\) is a maximum \(\iff\) there is no \(M\) augmenting path in \(G\). (is
\(M\) alternating if it starts and ends at an unsaturated vertex.)
\subsubsection{Augmenting path algorithm}
\label{sec:orgfe1e2df}
Input: Bipartite graph \(G = (X \cap Y, E)\), a matching \(M \subset E\).
Output: Either an \(M\) augmenting path or a cover of size \(\vert M \vert\).

Initialization: \(S = U\), \(Q = \emptyset\), \(T = \emptyset\)

Iteration: If \(Q = S\) STOP and return \(M\) (as maximal matching), \(TU(x
    \setminus S)\) (as min cover of size \(\vert M \vert\)) Else select \(x \in S
    \setminus Q\), \(\forall y \in N(x)\) with \(xy\in M\), DO if \(y\) is unsaturated,
then stop return a \(M\) augmenting path from \(U\) to \(y\). Else \(\exists w \in
    X\), \(yw \in M\) update, \(T = T \cap \{y\}\) and \(S = S \cup \{w\}\). Update \(Q
    = Q \cup \{x\}\). \footnote{I missed a lot of details here.}
\subsubsection{Proposition}
\label{sec:org5cd39f2}
\(G\) graph, \(M \subset E(G)\) is a matching. \(C \subset V(G) \implies \vert M
    \vert \le \vert C \vert\). Here \(C\) is the cover.

The idea is that every cover has to be bigger than the matching.
\subsubsection{{\bfseries\sffamily TODO} Proof of correctness}
\label{sec:orge914d45}
Stopping the algorithm: The algorithm can either stop with a \(M\) augmenting
path or it can stop with a maximum matching or a cover.

Proof of correctness: If the algorithm terminates with a matching \(M\) and a
cover \(T \cap (X \setminus S)\), we terminate at \(Q = S\), which means that we
have explored all the neighbours of \(S\) and they are all in \(T\). We want to
conclude that there exists no edge between \(S\) and \(Y-T\). (Because if there
is no edge between \(T\) and \(Y-T\), then \(T\) together \(S-T\) is a cover.)

If there is an edge from \(S\) to an unsaturated vertex \(y \in T\), then we
would have immediately put this vertex into \(T\). These two cases are not
possible.
\subsubsection{Comments}
\label{sec:org9b53299}
\(\vert M \vert = \vert T \vert + \vert X \setminus S\vert\). By the selection
of \(S\) and \(T\), vertices of \(T\) are put into \(T\) where their \(M\) partner is
put into \(S\).

\(\implies\), \(S = U \cap M\) partners of vertices in \(T\).
\subsubsection{Internet reference}
\label{sec:org337ca77}
\url{http://www.columbia.edu/\~cs2035/courses/ieor8100.F12/lec4.pdf}
\subsection{Theorem}
\label{sec:org747fc4d}
Repeatedly applying APA to bipartite graph produces a maximal matching and
minimal cover. The running time is \(O(V(G) \cdot e(G))\)

If we repeat APA \(\le n/2\) times. One running of APA considers each edge
\(\le 1\), implies \(O(e(G))\).
\subsection{Matching with weights}
\label{sec:org65d2514}
We have a weight function on the edges. \(w\colon E(K_{n, n}) \rightarrow \R\).

The goal is to find a perfect matching \(M\) such that the weight of the
matching which is the sum \(\sum w(e)\) is maximum.\footnote{Practical example: There is a company which has factories and corn
farms, the edges represent the profit the factory makes by producing corn from a
certain farm. There is more to this story. But I missed it.}

In general, we say that the weighted cover \(W\) is \(u_0, \cdots, u_n, v_1,
   \cdot, v_n\) such that \(u_i+v_j \ge w_{ij}\) for all \(i, j = 1, \cdots, n\). The
cost of \((u, v)\), \(c(u, v) = \sum u_i + \sum v_j\). (\textbf{The minimum weighted
cover problem} is to find a cover of minimum weight.)

The interesting part is that these two problems can be solved together.
\subsection{Duality lemma}
\label{sec:org21d40ec}
For all perfect matching \(M\) and cover \((u, v)\) in a weighted bipartite graph
\(G\), \(C(u, v) \ge w(M)\) (\textbf{Home work})

\subsubsection{Corollary}
\label{sec:org964814b}
If \(C(u, v) = w(M)\), then \((u, v)\) is a min-cost cover and \(M\) is a maximum
weight matching.
\subsection{Algorithm for Maximal weighted matching}
\label{sec:org9bf63b9}
Equality: Subgraph \(G_{u, v} \subset K_{n, n}\), a spanning subgraph which has
the same vertex set and the edges at those \(x\) and \(y\) where \(w_{i, j} =
   u_i+u_j\).
\subsection{Hungarian algorithm}
\label{sec:orgedce0ef}
Input: A matrix \(w_{i, j}\) of weights of the edges of \(K_{n, n}\) with points
\(X = \{x_1, \cdots, x_n\}\), \(Y=\{y_1, \cdots, y_n\}\).

Idea: Iteratively adjust a cover \((u, v)\) until \(G_{u, v}\) has a perfect
matching.

if \(G_{u, v}\) has a perfect matching, then \((u, v)\) and \(M\) are both optimal.
Initial \(u_i = \max \{W_{i, j}\colon j=\{1, \cdots, n\}\}\) and \(v_i =0\). Note
that this is a cover and \(u_i + v_j \ge w_{i, j}\) for all \(i, j\). 

Iteration: Create \(G_{u, v}\), using APA and find a maximal matching \(M\) and a
minimum vertex cover \(Q\) and \(Q\) will be equal to \(T \cup R\) (where \(T = Y
   \cap Q\) and \(R = X \cup Q\))

If \(M\) is a perfect matching, then we are done. (By corollary of the duality
lemma.)

Else \(\varepsilon = \min\{u_i + v_i -w_{i, j}\colon x_i \in X \setminus R,
   y_j \colon Y\setminus T\}\) (all elements are positive here.)

We update as follows: \(u_i = u_i - \varepsilon\) if \(x \in X \setminus R\) and
\(V_j = v_j+\varepsilon\) if \(y \in T\). Now you iterate.

Why is the update \((u, v)\) still a cover? It involves 4 cases depending of
where the pair \((i, j)\) goes to.

\begin{enumerate}
\item If \(x_i \in R\) and \(y_j \in Y \setminus T\).
\(u_i, v_j\) are unchanged.
\item \(x_i \in R, y_j \in T\) implies that \(u_i + v_j\) grew by \(\varepsilon\) which
is okay.
\item \(x_i \in X \setminus R\), \(y_j \in T\), \(u_i - \varepsilon, v_j +
      \varepsilon = u_i + v_j\)
\item x\(_{\text{i}}\) \(\in\) X \(\setminus\) R, y\(_{\text{j}}\) \(\in\) Y \(\setminus\) T\$. So \(u_i + v_j \ge w_{i,
      j}\).
\end{enumerate}
\section{Lecture 8 \textit{<2018-10-31 Wed>}}
\label{sec:orga25056a}
\textbf{Input}: \((w_{i, j})_{i, j =1}^n\) weights or \(E(K_{n, n})\), \(X = \{x, \cdots,
   y_n\}\), \(Y = \{y, \cdots, y_n\}\)

\textbf{Initialization}: \(u_i = \max_\{w_{i, j}, j\cdots n\}\), \(v_j = 0\)

\textbf{Iteration}: For \(m\), \(G_{u, v}\), \(V(G_{u, v} = V(K_{n, n}), E(G_{u, v}) =
    \{x_iy_j \colon w_ij = u_i + v_j\}\)

Find a maximal matching \(M \subset G_{u, v}\) and min vertex case \(Q = T \cup
    R\).

If \(M\) is perfect matching, then return (as max weighted is perfect
matching.), \(R = X \cap Q, T = Y \cap Q\). \((u, v)\) as a minimum cost cover.

Else \(\epsilon = \min\{u_i + v_j - w_{ij}\colon x_i \in X \setminus R, y_j
    \in Y \setminus T \}\) Update \(u_i = u_i - \epsilon\) if \(x_i \in X \setminus
    R\) and \(v_j = v_j + \epsilon\) if \(y_j \in T\).

\textbf{Remark}: \(G\) is bipartite, define \(w_{i, j} \iff w_{i, j} = 1 \iff x_iy_j
     \in E(G)\) vertex cover \(G\) implies \(u, v\) characteristic \((011)\) vectors of
 \(C\), implies cover of \(w_{ij}\), \(w_{i, j} \le u_i + v_j\). True since if
 \(w_{i, j} = 1\) then \(x_iy_j \in E(G)\), then \(x_i\) or \(y_j \in C\), then
 \(u_i\) or \(v_j =1\).

\begin{center}
\begin{tabular}{rrrrrr}
x & 0 & 0 & 0 & 0 & 0\\
\hline
5 & 1 & 2 & 3 & 4 & 5\\
8 & 6 & 7 & 8 & 7 & 2\\
5 & 1 & 3 & 4 & 4 & 5\\
8 & 3 & 6 & 2 & 8 & 7\\
5 & 4 & 1 & 3 & 5 & 4\\
\end{tabular}
\end{center}

Excess matrix
\begin{center}
\begin{tabular}{rrrrrr}
x & 0 & 0 & 0 & 0 & 0\\
5 & 4 & 3 & 2 & 1 & 0\\
8 & 2 & 1 & 0 & 1 & 6\\
5 & 4 & 2 & 1 & 1 & 0\\
8 & 5 & 2 & 6 & 0 & 1\\
5 & 1 & 4 & 2 & 0 & 1\\
\end{tabular}
\end{center}

Now we form the graph with \(0\) edges and find a perfect matching.

\begin{center}
\begin{tabular}{rrrrrr}
x & 0 & 0 & 1 & 1 & 1\\
\hline
4 & 3 & 2 & 2 & 1 & 0\\
7 & 1 & 0 & 0 & 1 & 6\\
4 & 3 & 1 & 1 & 1 & 0\\
7 & 4 & 1 & 6 & 0 & 1\\
4 & 0 & 3 & 2 & 0 & 1\\
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{rrrrrr}
x & 1 & 0 & 1 & 2 & 2\\
\hline
3 & 3 & 1 & 1 & 1 & 0*\\
7 & 2 & 0* & 0 & 2 & 7\\
3 & 3 & 0 & 0* & 1 & 0\\
6 & 4 & 0 & 5 & 0* & 1\\
3 & 0* & 2 & 1 & 0 & 1\\
\end{tabular}
\end{center}

Now we end up with a perfect matching in the equality subgraph. (The ones
labelled *)

\begin{center}
\begin{tabular}{lrrrrr}
x & 0 & 0 & 0 & 0 & 0\\
\hline
 & 1 & 2 & 3 & 4 & 5*\\
 & 6 & 7* & 8 & 7 & 2\\
 & 1 & 3 & 4* & 4 & 5\\
 & 3 & 6 & 2 & 8* & 7\\
 & 4* & 1 & 3 & 5 & 4\\
\end{tabular}
\end{center}

The above table represents the cover in the original graph.

Perfect matching of weight \(5 + 7 + 8 + 4= 28\) and \(C(u, v) = 3 + 7 + 3 + 6 +
   3+ 1 + 1 + 2 + 2 = 28\).
\subsection{Proof}
\label{sec:org07bb33e}
If we add edges at every step in the graph from which we get the matching, we
would be done. But we are not exactly doing it.

Observations: \(\vert Q \vert = \vert M \vert\), no \(M\) edge is covered twice by \(Q\).

\(T = \{y \in Y \colon \exists M\) alternating \((U, y)\) path \(\}\).

\(R = \{x \in X \colon \nexists M\) alternating \((U, Y)\) path \(\}\).

where \(U = \{x \in X \colon x\) is \(M\) unsaturated \(\}\).

For termination of the Hungarian algorithm, count for \textbf{the number of vertices
that are reached from \(U\) on an \(M\) alternating path}. This quantity grows in
each iteration. (or \(M\) augmenting path, which implies that there is a larger
matching.)

The edges of \(M\) alternating path starting at \(U\) remain in \(G_{u, v}\). Edges
can be lost only between \(T\) and \(R\). But these edges are not participating
in the alternating path. In \(M\) alternating path, vertices of \(T\) are only
connected to vertices in \(S = X - R\).

By the choice of \(\varepsilon\), there is at least one pair \(x_i y_j\) such
that \(x_i \in X \setminus R\), \(y_j \in T\),such that \(x_i y_j\) is a new edge
in the equality sub-graph.

This means that after \(\le \frac{n}{2}\) iterations, or \(M\) unsaturated \(y\in
   Y\) is reached via a \(M\) alternating path, which means that the matching is
growing, and the matching can grow at most \(n/2\). Thus after \(\frac{n^2}{4}\)
iterations.
\subsection{Connectivity problem}
\label{sec:org942af5d}
\subsubsection{Definition (Vertex cut)}
\label{sec:org8b13616}
A vertex cut of a graph \(G\) is a set of vertices such that \(G-S\) is
disconnected.\footnote{In a good connected graph, you don't want a vertex set to be small.}
\subsubsection{Definition (Connectivity of G)}
\label{sec:org8b6cedd}
Connectivity of \(G\), denoted by \(\kappa\), is the minimum size of the vertex
cut. If your graph is disconnected to begin with, then this is zero.

By definition, for a clique, \(K(K_n) = n-1\). The empty graph is "considered"
to be disconnected.
\subsubsection{Examples}
\label{sec:org11ceb66}
\(K(K_{n, m})= \min\{n, m\}\). Proof: \(\le\), Given a vertex cut of size
\(\min\{m, n\}\), smaller side

\(\ge\) Now we remove \(\{m, n\} - 1\), vertices of \(S\), \(K_\{n, m\} - S\), and
through them everybody else can be reached.
\subsubsection{Proposition}
\label{sec:org6a0faf3}
For all \(G\), \(K(G) \le n-1\). The clique is \(K(G) = n-1 \iff G = K_n\).

\(K(G) \le \delta(G)\), here \(\delta\) is the min degree. This is kinda clear,
because we can pick a vertex with the minimum degree and remove all it's
neighbours.

\(K(Q_d)\), the one skeleton of the \(d\) dimensional cube.

\(E(Q_d) = \{uv \colon\) \(u\) and \(v\) differ in exactly one coordinate \(\}\).
From the proposition, the minimum degree is \(d\).

I didn't write the rest of the argument. But doesn't look so hard. The proof
was by induction.
\section{Lecture 9 \textit{<2018-11-07 Wed>}}
\label{sec:org618503b}
\subsection{Connectivity of graph}
\label{sec:orgb59e060}
\(G \neq K_n\), then \(K(G) = \min \{ \vert S \vert \colon G - S \textup{ is not
   connected } \}\).

\(G = K_n\), \(K(G) = n-1\).
\subsection{Proposition}
\label{sec:org61b116e}
\(K(G) \le v(G) - 1\) and \(K(G) \le \delta(G)\).
\subsection{Extremal questions}
\label{sec:org6631472}
Given \(n\) and \(k\), what is the smallest number \(e\) of edges that there exists
as \(n\) vertex \(k\) connected  graph with \(e\) edges.
\subsection{Proposition}
\label{sec:org6cdd719}
For all \(k \ge 2\), there exists a \(k\) connected graph on \(n\) vertices with
the ceil of \((n-k)/2\) edges.
\subsection{Theorem (Chvatal-Erdos)}
\label{sec:orge419c16}
If \(G \neq K_2\) and its connectivity \(K(G) \ge \alpha(G)\). \(\alpha(G)\) is the
size of the largest independent set of vertices. And \(\alpha'\) is the size of
the largest matching \footnote{We use the convention that the prime is the corresponding to edges.}

Then \(G\) is hamiltonian.
\subsubsection{Proof}
\label{sec:orgdea8751}
Take a cycle in \(C \subset G\) which is the longest. If the length of \(C\) is
\(n\), we are done. So we can assume the length of \(C\) is less than \(n\).

Let \(H\) be a component of \(G -C\).

\(k \le \delta(G)\). The length of the longest cycle is at least \(\delta\).
Take the largest path in \(G\) and the end points of \(P\) only have neighbours
on \(P\), otherwise the path could be extended. The farthest neighbour of \(w\)
of \(x\) on \(P\) has distance at least \(\delta(C)\).

This means that the segment \(P[x, w] + xw\) forms a cycle of length \(\ge
    \delta(G) + 1\).

Back to \(H\). Let name the vertices which have an edge to \(H\) as \(v_i\). There
exits at least \(k\) vertices on \(C\) which have an edge to \(H\) (this is
because of \(k\) connectedness; otherwise we could separate \(C\) from \(H\) by
the deletion of strictly less than \(k\) vertices, which is a contradiction.)

Notice that two adjacent vertices in \(C\) cannot have an edge to \(H\),
otherwise, we can extend \(C\) by entering \(H\) and coming back. We call
\(v_{i}^{+}\) denote the vertices that are the vertices that follows \(v_i\) on
the cycle. We now know that all off \(v_{i}^{+}\) is distinct from \(v_i\). 

We can see that there cannot be two edges between \(v_{i}^{+}\) and
\(v_{j}^{+}\), one can see this by drawing an easy diagram, for one can form a
bigger cycle than \(C\), which is a contradiction.

This implies that \(\{v_i^+, \cdots, v_k^+\}\) is an independent set of size
\(k\). This union with any vertex in \(H\) is an independent set. This is a
contradiction because \(\alpha(G) \ge k+1\), which is not what we assumed.
\subsection{Definition (Disconnecting set of edges)}
\label{sec:org1b305ea}
\(F\) is a disconnecting set of edges if its removal makes the graph
disconnected, i.e., \(G-F\) is disconnected.

\(\kappa'(G) = \min\{\vert F \vert \colon F \subset E(G) \textup{ is a
   disconnecting of edges}\}\)

This is the \textbf{edge connectivity} of \(G\). \(G\) is called \(k\) edge connected,
\(k'(G) \ge k\).
\subsection{Definition}
\label{sec:org30c67b5}
A subset \(S \subset V(G)\), then an edge-cut of the Multi-Graph is an edge-set
of the form \([S, \bar{S}] = \{xy \colon x = S, y \in \bar{S}\}\). For some
subset \(S, \emptyset \neq S \neq V(G)\). Here \(\bar{S} = V(G)\setminus S\), the
set theoretic complement.
\subsection{Observation}
\label{sec:org17dd832}
\(K'(G) = \min\{[S, \bar{S}] colon S\subset V(G), S\neq \emptyset, S \neq V(G)
   \}\)
\subsubsection{Proof}
\label{sec:org4c4f8bf}
If \(F \subset E(G)\) is a disconnecting set of edges with \(\vert F \vert
    \subset K'(G)\), then let \(S\) be a components of \(G - F\), then \([S, \bar{S}]
    \subset F\). Since \(F\) is minimal, this implies that \(F = [S, \bar{S}]\).
\subsection{Bounds}
\label{sec:org1016743}
\begin{enumerate}
\item Initial bound, \(k'(G) \le \delta(G)\).
\item \(\kappa'(G) > \kappa(G)\) is true for simple graphs.

\textbf{Proof}: The proof is easy. Try to show that there is a vertex cut of size
\(\kappa'(G)\) whose removal disconnects \(G\).

Take an edge cut such that the size \(\vert[S, \bar{S}]\vert = K'(G)\).

Case 1: \(G\) contains \(K_{\vert S \vert, \vert \bar{S} \vert}\) on \(S\) and
\(\bar{S}\). Then the statement is trivially true, since \(K'(G) = \vert S,
      \bar{S}\vert = \vert S \vert \vert \bar{S}\vert = \vert S \vert (n - \vert
      S \vert) \ge n - 1\ge \kappa(G)\).

Case 2: We don't have a complete bipartite graph, so we can identify
vertices that we will disconnect, \(x\in S\), \(y\in \bar{S}\) such that \(xy
      \notin E(G)\).

\(T_1\) is the set of neighbours \(N(x) \cap \bar{S}\) on the other side. \(T_2
      = \{w \in S \setminus x \cap S \colon N(w) \cap \bar{S}\} \neq \emptyset\).
The removal of \(T_1\) and \(T_2\) separate \(x\) and \(y\). Now \(\vert T_1 \cap
      T_2 \vert \le \vert[S, \bar{S}]\). Because there is an injection from the
left set to the other one, given by if \(w\in T_1, take xw\). \(w\in T_2
      \mapsto wu_w\).

Note \(S\) is just one side that is separate from the other side.
\end{enumerate}
\subsection{Is graph \(G\) \(k\) connected?}
\label{sec:orge4b5c86}
It's definitely in co-NP. If it's not \(k\) connected, we get a set a vertices,
and, we'll be able find it in polynomial time.

But is it in \(NP\)?

\(1\) connectedness if in \(P\).

But \(2\) connectedness is in \(P\). There are only a \(n^2\) number of vertices.
Hence polynomial.

But we want to know about \(k\) connectivity, when \(k\) is the function of \(n\).
\subsection{Theorem (A characterization of \(2\) connectivity)}
\label{sec:org972be5d}
\(G\) is \(2\) connected if and only if for all \(x, y \in V(G)\), they are on a
cycle.\footnote{It is true that for \(k\) connectedness, any \(k\) vertices are on a cycle,
but the other direction is not true.}

\(G\) is \(2\) connected if and only if for all \(x, y \in V(G)\) if there exist
\(2\) internally disjoint \(x, y\) paths. \footnote{This can be generalized in a very straightforward way.}
\section{Lecture 10 \textit{<2018-11-14 Wed>}}
\label{sec:orgac0e539}
\subsection{Menger's theorem (VMT)}
\label{sec:org3b6cf60}
A graph \(G\) is \(k\) connected if and only if for all pairs of vertices \(x, y
   \in V(G)\), there exits \(K\) pairwise internally disjoint paths.
\subsubsection{Remarks}
\label{sec:org279b63f}
\begin{enumerate}
\item This implies that \(k\) connectivity is in \(NP\) intersection co-NP. It
takes \(O(kn)\) to check that they are internally disjoint. There are
\(O(n^2)\) pairs to check
\item For \(k=2\), the VMT says that \(G\) is \(2\) connected if and only if for
every \(x, y \in U(G)\) is a cycle.
\end{enumerate}
\subsubsection{Proof of (\(\Leftarrow\)) VMT}
\label{sec:org0aead95}
Suppose for a contradiction that there are \(k\) internally disjoint vertices
between every vertices, and \(\kappa(G) \le k-1\). Let \(S\) be a such a
separating set. 

Let \(S\) be such a separating set which separates \(x\) from \(y\), then every
\(xy\) path passes through \(S\), and pigeon-hole implies that two halfs share a
vertex of \(S\). This is a contradiction.
\subsubsection{Proof of \(\implies\) of VMT for \(k=2\)}
\label{sec:org70856a5}
Assume \(K(G) \ge 2\), need a cycle containing \(x, y \forall\) pairs \(x, y \in
    V(G)\).

Induct on \(d(x, y) = \{\vert e(P)\vert \colon P \textup{ a xy path }\}\).

\textbf{Base case}: \(d(x, y) = 1\), \(\kappa'(G) \ge \kappa(G) \ge 2\). Implies \(G
    \setminus \{xy\}\) is still connected \(\implies xy\) path \(P\) in \(G\setminus
    e \implies P \cap \{e\}\) is a cycle which contains \(x, y\).

\textbf{Induction step}: \(d(x, y) = d\), let \(P\) be a path of length \(d\). Let \(v\) be
 the last vertex before \(y\) on \(P\). Induction says that some \(C\) containing
 \(x\) and \(v\).

If \(y\in C\), we are done. If not, there exits a \(xy\) path \(Q\) in
\(G\setminus \{v\}\) as \(G\) is \(2\) connected. Now, it's easy to construct a
cycle from \(x\) to \(y\).

Let \(z\) be the last \(v_x\) of \(C\) on \(Q\) if it exits. Let \(D\) be \(C\setminus
     [z, v]\) such that \(x \in D\). Now \(C' = D \cup Q\vert[x, y] \cup \{xy\}\)
cycle containing \(x\) and \(y\).

If no such \(z\) exists, then it's straightforward to construct a cycle.
\subsection{Edge Menger's theorem}
\label{sec:org2210621}
A graph \(G\) is \(k\) connected if \(\kappa'(G) \ge k\) if and only if for all \(x,
   y \in V(G)\), there exists pairwise edge disjoint \(x-y\) paths.
\subsection{Local version of Menger's theorem}
\label{sec:org9b13745}
\subsubsection{Separating set}
\label{sec:org3e93b41}
\begin{enumerate}
\item A set \(S \subset V(G)\) is an \(xy\) separating set if \(x\) and \(y\) are in
different connected components of \(G\setminus S\).
\item \(\kappa(x, y) = \min\{\vert s \vert \colon S \textup{ is a xy separating set}\}\)
\item \(\lambda(x,y) = \max\) size of a family of pairwise disjoint \(xy\) paths.
\end{enumerate}
\subsubsection{Local version of theorem}
\label{sec:org1da3394}
For all graphs \(G\) and \(x, y \in G\), we require that \(x\) and \(y\) are not
adjacent edges.

For all \(x, y\), \(\kappa'(x, y) = \lambda'(x, y) = \max\) size of family of
pid \(xy\) paths. Here \(\kappa'\) is the minimum \(\vert F \vert\) such that \(x\)
and \(y\) are in different components of \(G\setminus F\).
\subsubsection{Local theorem implies Global}
\label{sec:org8364647}
What we need to do is that for all \(x, y \in G\), \(\exists \ge k = \kappa(G)\)
pid paths.
\begin{enumerate}
\item \(x\) and \(y\) are not adjacent (xy \(\neq\) E(G)) implies \(\kappa(G) \le
       \kappa(x, y)\le \lambda(x, y)\). The local theorem says that the last term
is at least \(\lambda(x, y)\), implies \(\ge k\) pid \(xy\) paths.
\item For \(xy = e\), \(\kappa(G-e) \ge K(G) - 1\). Suppose for a contradiction
that \(S\) separates \(G-e\) and \(\vert S \vert \le \kappa - 2 \le n-3\). We
know as \(\vert s \vert < K\), \(G\setminus S\) is connected implies that
\(G\setminus S\) must have a "bridge" \(e\). Meaning we have two disconnected
sets only connected by \(e\) between \(T\) and \(T'\).

Without loss of generality \(x \in T\), and \(\vert T \vert \ge 2\). But then
\(S \cap \{x\}\) is a separating set of \(G\) of size \(\le \kappa - 1\).
\item If \(xy\) is an edge in \(E\). Removing it means that \(\kappa(G-e) \ge k-1\),
then 1 implies that \(k-1\) pid \(xy\) paths in \(G-e\) and \(e=xy\) adds another
path.
\end{enumerate}
\subsection{Flow networks}
\label{sec:org0e4e44f}
\subsubsection{Example}
\label{sec:org9b00db9}
A graph was drawn. 
\subsubsection{Definition}
\label{sec:org21e94b9}
A network is a quadruple \((D, s, t, c)\) where \(D\) is a directed (multi)
graph. \(s \in V(D)\) is the source vertex and \(t\) is the sink vertex. \(c
    \colon E(D) \rightarrow \R^{+}\) is the capacity.

A flow is \textbf{feasible} if
\begin{enumerate}
\item For all \(v \neq s, t\), the net flow in is equal to the net flow out, i.e,
for all \(v\neq s, t\), \(\sum f(uv) =f^{-}(v) = f^{+}(v) = \sum(vu)\). This
is called the \emph{conservation constraints}. \footnote{I think there is a typo in the last \(\sigma\) part.}
\item For all directed edges, we require that the flow on the edge is
non-negative and at most the capacity. This is called \emph{capacity
constraint}
\end{enumerate}

The \textbf{value} of of a flow is the net flow into the sink, \(f^{-1}(t) -
    f^{+}(t) = val(f)\).

A \textbf{max flow} is a feasible flow with maximum \(\val(f)\).
\subsubsection{Problem}
\label{sec:org43fb4de}
Given a network flow, we need to find a max value and if possible find a max
flow.
\subsubsection{Homework}
\label{sec:org8a02cc0}
For any \(Q \subset V(D)\), with \(s\in Q\) and \(t\in \bar{Q} = V(D) \setminus
    Q\), \(\val(f) = \sum_{e\in [Q, \bar{Q}]} f(e) - \sum_{e\in [\bar{Q}, Q]}
    f(e)\)
\subsubsection{Definition}
\label{sec:org569784f}
Given \(Q \subset V(D)\), \(\bar{Q} = V \setminus Q\), with \(s\in Q, t\in
    \bar{Q}\), the capacity of the cut is capacity \(\cap[Q, \bar{Q}] = \sum_{e\in
    [Q, \bar{Q}] c(e)}\)
\subsubsection{Lemma}
\label{sec:org2c52162}
Weak duality: If \(f\) is a feasible flow and \([Q, \bar{Q}]\) a source/sink
cut, then the value of the flow \(\val(f) \le \cap([Q, \bar{Q}])\)
\begin{enumerate}
\item Proof
\label{sec:orgf8edf3d}
Fix \(f\) and \([Q, \bar{Q}]\). \(\val(f) = \sum_{[Q, \bar{Q}]} f(e) -
     \sum_{[\bar{Q}, Q]} f(e) \le \sum_{[Q, \bar{Q}]} c(e) - 0 = \cap([Q,
     \bar{Q}])\)
\end{enumerate}
\subsection{Theorem (Ford-Fulkerson) (Max-flow min-cut theorem)}
\label{sec:org0393a1b}
Let \(f\) be a flow of max value and \([Q, \bar{Q}]\) a source-sink cut of
minimum capacity, then the \(\val(f) = \cap([Q, \bar{Q}])\).
\section{Lecture 11 \textit{<2018-11-20 Tue>}}
\label{sec:org9ac3d44}
\subsection{Network}
\label{sec:org9ef958a}
\(D\) is a directed multigraph. \(s = V(D)\), the source vertex and \(t \in V(D)\)
the sink vertex and \(c\colon E(D) \rightarrow \R_{\ge 0}\) capacity
function.

\textbf{Flow} is a function \(f\colon E(D) \rightarrow \R\)

Flow is function \(E(D) \rightarrow \R\). For feasible flow
\begin{enumerate}
\item For every \(v\) that is not \(s\) and \(t\), \(\sum_{(v,u) \in E} f(v, u) =
      f^{+}(v)\)
\item \(\forall e \in E\), \(0 \le f(e) \le c(e)\). The value of the flow is
whatever goes into the sink \(\val(f) = f^{-}(t) - f^{+}(t)\).
\end{enumerate}

The \textbf{maximum flow} is a feasible flow of maximum value.
\subsection{Weak duality}
\label{sec:org579cc2b}
For every feasible flow \(f\) and source sink cut \([S, \bar{S}]\), the value of
the \(f \le \cap(S, \bar{S})\), in particular, the equality happens if \(f\) is a
maximum flow and \([S, \bar{S}]\) is a min-cut.

\([S, \bar{S}] = \{(u, v) \in E(D) \colon u \in S, v \in \bar{S}\}\) is a
source sink cut if \(s\in S\) and \(t\in \bar{S}\).

\([S, \bar{S}]\) is a min cut if its capacity \(\cap(S, \bar{S}) = \sum_{u \in
   S, v \in \bar{S}} c(u, v)\) is minimum among source/sink cut.
\subsection{Max Flow Min cut theorem (Ford-Fulkerson, 1956)}
\label{sec:org5ce5278}
Let \((D, s, t, c)\) be a network. Let \(f_{\max}\) be a max flow on \(D\) and
\([S_{\min}, \bar{S}_{\min}]\) a min cut, then \(\val(f) = \cap (S_{\min},
   \bar{S}_{\min})\).

\href{https://en.wikipedia.org/wiki/Ford\%E2\%80\%93Fulkerson\_algorithm}{Wikipedia}
\subsubsection{Proof}
\label{sec:org443729c}
\(\le\) direction is just the weak duality.

\(\ge\) direction. We will find a source sink cut such that the capacity of
the source sink cut is equal to the value of the maximal flow.

That is, \(\cap(S, \bar{S}) = \val(f_\max)\).

\(S = \{v \in V(D) \colon \exits f \textup{augmenting path from s to v}\}\)

Observation \(t \in \bar{S}\) and \(s \in S\). This is because if there is a \(f\)
augmenting path from \(s\) to \(t\), then \(f\) is not maximum, but we know that
\(f\) is maximum, a contradiction.\footnote{An \(f\) augmenting path by definition means from source to sink. Our
definition here means the same definition except that the end vertex need not be
the sink.}

\(t\in \bar{S}\), \(s\in S\), 
\begin{enumerate}
\item \([S, \bar{S}]\) is a source/sink cut.
\item \((u, v) \in [S, \bar{S}]\), \(f(u,v) = c(u, v)\). \((u, v) \in [\bar{S}, S]\)
implies that \(f(u, v) = 0\). Because if not, we can add them to \(S\).
\end{enumerate}

Now we see that the capacity of the cut \(\cap(S, \bar{S}) = \sum c(u, v) =
    \sum_{(u, v) \in [S, \bar{S}] f(u, v) - \sum_{(u, v) \in [\bar{S}, S]} f(u,
    v) = \val(f_\max)\) the last statement is a homework problem.
\subsection{Augmenting path}
\label{sec:org29668a8}
An \(s, t\) path \(s = v_0e_1v_1e_2v_2 \cdots v_{k-1}e_k v_{k} = t\) in the
underlying undirected graph \(G\) of a network \(D\). This is called an
\$f\$-augmenting path if for every \(i\), 
\begin{enumerate}
\item \(f(e_i) < c(e_i)\) is true if \(e_i\) is a "forward" edge.
\item or \(f(e_i) > 0\) if \(e_i\) is a backward edge.
\end{enumerate}

The tolerance of a \(f\) augmenting path \(P\) is just the minimum of the values
\(\min \{E(e) \colon e \in E(P)\}\) where \(E(e) =\), \(c(e) - f(e)\) if \(e\) is
forwards and \(f(e)\) when \(e\) is backward.

If we define a \(f\) augmenting path, we can improve the value of the path. You
can improve the value of the path by the tolerance of the path.
\subsection{Lemma}
\label{sec:orgf512669}
Take a feasible flow and an \(f\) augmenting path with tolerance \(z\), then we
define a new flow \(f'\) on the edges such that \(f'(e) = f(e) + z\) if \(e\) is
forward in \(P\) and \(f(e) - z\) if \(e\) is a backward edge. And if the edge is
not on the path, you do nothing.

Then \(f'\) is feasible and the \(\val(f') = \val(f) + z\).
\subsubsection{Proof}
\label{sec:org59f3b77}
Capacity constraints hold by the definition of \(z\).

Conservation constraints holds because: if we have a vertex \(v\in V(P)\),
then. 

We had four cases and four diagrams. Basically given a vertex, there is one
vertex leaves the vertex and one vertex that comes to \(z\). We can argue for
each of these cases.
\subsection{Corollary}
\label{sec:org231d43d}
If there exits an \(f\) augmenting path implies that \(f\) is not maximum.
\subsection{Local Vertex Menger's theorem}
\label{sec:orgc8829a0}
For all \(x, y \in V(G)\), \(xy\notin E(G)\), \(\kappa(x, y) = \lambda(x, y) =
   \max\{\vert P \vert \colon P\) is a set of pairwise internally disjoint \(x, y\)
path \(\}\).
\subsubsection{Proof}
\label{sec:orgff75c41}
The idea is to build a network so that the Ford-Fulkerson theorem implies
it.

\((D, x^{+}, y^{-}, c)\), \(V(D) = \{v^{-1}, v^{+}, v\in V(G)\}\), \(E(D)
    =\{(u^{+}, v^{-} \colon uv \in E(G)\} \cap \{(v^{-1}, v^{+} \colon v \in
    V(G)\}\).

\(c(v^-v^{+}) = 1\) for all \(v \in V(G)\), and \(c(u^{+}v^{-} = \infty\).

If there is an \(xy\) separating set in \(G\), this corresponds to a source sink
cut in \(D\).

\(S = \{v^-, v^{+}, v\in Q\} \cap \{u^{-1}\colon u \in C\} \subset V(D)\) and
\(\cap (S, \bar{S}) = \vert C \vert\). If \(v \in S\), there exits no
\(v^{+}w^{-}\) edge to \(w \notin S \cap Q\).

Minimum cut \(S, \bar{S} \le K(x, y)\)

\(\ge\) take a minimum cut in \(D\). There does not exist an edge \(v^{+}u^{-}
    \in [S, \bar{S}]\).

The set \(C = \{u \in V(G) \colon (u^{-1}, u^{+}) \in [S, \bar{S}]\}\) is an
\$x, y\$-separating set in \(G\) and the size \(\vert C \vert = \cap(S,
    \bar{S})\).

\$\(\lambda\)(x, y) \(\le\) \maxval(f) = \mincap(S, \bar{S}) = \(\kappa\)(x, y).\$ If you
have a family of internally disjoint, this in the network correspond to
several flows in the network. You definitely could create a flow.
\section{Lecture 12 \textit{<2018-11-21 Wed>}}
\label{sec:orgd52ecfd}
\subsection{LMVT proof}
\label{sec:orge4cb4b5}
\(V(D) = \{u^{+}, u^{-}, u \in V(D)\}\)

\(E(D) = \{u^{+}, v^{-1}, uv \in E(G)\} \cup \{(v^{-1}, v^{+}\colon v\in
   V(G)\}\)

\(c(v^{-}, v^{+} =1\) for all \(v \in V(D)\).

\(c(u^+, v^-) = \infty\) for all \(uv \in E(D)\)

\((D, x^+, y^-, c)\)

The maximum value of a feasible flow is the minimum capacity \((S, \bar{S}) =
   \kappa(x, y)\).
\subsection{Ford Fulkerson algorithm}
\label{sec:orgd5eb709}
\textbf{Initialization}: Network \((D, s, t, c)\). Choose an initial flow \(f \eq 0\).

\textbf{Iteration}: Look for augmenting paths to improve the algorithm. Explore
 network for \(f\) augmenting paths starting from \(s\) (can be done using BFS.)
 Collect vertices reached in set \(S\).

Once you're done we have two cases. You didn't have an augmenting path which
implies that we have reached a maximum. If there is \(t\in S\), return
augmenting path and improve the flow.

If \(t\in S\), return augmenting path and an improved flow.

else return \(f\) as max flow and \([S, \bar{S}]\) as min cut with \(\val(t) =
    \cap(S, \bar{S}\)

\subsubsection{Integrability theorem}
\label{sec:org1c9e5dd}
If \(c\) is a function from the edges to the natural numbers, then the
Ford-Fulkerson algorithm terminates with a flow with integer values.
\begin{enumerate}
\item Proof
\label{sec:org8efd1bc}
Proof is by induction on the number of times the flow has been improved.
And noting that the tolerance of any \(f\) augmenting path is integer since
both are integers and hence the improved flow will also be an integer.

The algorithm hence terminates in at most maximum of the capacity steps.
\end{enumerate}
\subsubsection{Corollary}
\label{sec:orgace692a}
If the capacities are integers, then there exists a maximum flow that can be
represented as the flow of \(\val(f)\) many unit flows \$f = g\(_{\text{1}}\) + g\(_{\text{2}}\) +
\(\cdots{}\) + g\(_{\val}\)(f) with \(val g_i = 1\).
\subsubsection{Continuation}
\label{sec:org30b55fb}
By the IT theorem there exist flows \(g_1, \cdots, g_k\) from \(x^+\) to \(y^-\)
each of these are the form \(x^+v_{i,1}^-v_{i,1}^+v_{i, 2}^+, \cdots,
    v_{i1,l_1}^-v_{i1,l_1}^+y^-\)

Hence the \(xy\) path \(xv_{i, 1}v_{i, 2} \cdots v_{i, e_1}y\) in \(G\) are
pairwise internally disjoint paths.
\subsection{Partitioning triples}
\label{sec:orga3258d2}
We want to partition \(\binom{n}{3}\) triples into "perfect matchings" that are
pairwise disjoint. You need to have \(3 \vert n\)

This number will turn out to be \(\frac{n}{3} \cdot \frac{(n-1)(n-3)}{2}\).

For \(6\) vertices, we could take the set and the complement. Which is just
\(\binom(6, 3)\).
\subsection{General version of Partitioning}
\label{sec:orgd0518cc}
Let \(k, n\) integers and \(k\vert n\). Is it possible to partition the family
into \(\binom{n}{k}\) sets into pairwise disjoint perfect matchings. Perfect
matching is a set of \(n/k\) pairwise disjoint edges.

The answer is yes for every \(k\).
\subsubsection{Definition}
\label{sec:org754ed03}
\(m = n/k\) is the number of sets in the perfect matching.

\(M = \binom{n}{k}/(n/k) = \binom{n-1}{k-1}\) The number of perfect matchings needed

Given an integer \(1\ le l \le n\) a \(m\) partition of \([l]\) is a multi-set \(r
    = \{A_1, \cdots, A_m\}\) consisting of pairwise disjoint sets whose union is
\([l]\). (\footnote{Repetition is allowed only for \(\emptyset\). Because sets are disjoint.})
\subsubsection{Remark}
\label{sec:orgf892ef8}
Restriction of a perfect matching to \([l]\) is a \(m\) partition.
\subsubsection{Proposition}
\label{sec:org83b67c6}
For every \(l\) there exists \(M\), \(m\) partitions of \([l]\), called \(A_1,
    \cdots, A_2, \cdots, A_M\) such that for every subset of \([l]\), occurs in
exactly \(\binom{n-l}{k-\vert S\vert}\) of the \(m\) partitions. (The empty set is always
counted with multiplicity)
\subsubsection{Remarks}
\label{sec:org5e61318}
\begin{enumerate}
\item If \(\vert S \vert > k\), the statement says it occurs \(0\) times. Only \(\vert
       S \vert \le k\) occurs.
\item \(l=n\), There exists \(M\), \(m\) partitions \(=0\) and \(1\) when \(k = \vert S
       \vert\). \(M\), \(m\) partitions in which every \(k\) occurs exactly once and
nothing else. This means that there exists a partition \(A_1, \cdots, A_M\)
are perfect matchings consisting of \(k\) sets that partition
\(\binom{n}{k}\). Thus the theorem is proved.
\end{enumerate}
\subsubsection{Proof of Proposition}
\label{sec:org59bc665}
When \(l = 1\), \(A_i = \{\{1\}, \emptyset, \emptyset, \cdots, \emptyset\}\)
(the empty set occurs for \(m-1\) number of times.)

If \(s = \{1\}\), then \(s\) occurs \(M\) times. \(\binom{n-l}{k-s} =
    \binom{n-1}{k-1} = M\)

When \(s\) is the empty set. Then \(S\) should occur \(\binom{n-1}{k-0} =
    \binom{n-1}(k}\). Count: \(M(m-1) = \binom{n-1}{k-1}(n/k - 1)\) this is true as
well. I missed the rest of the proof.
\section{Tutorial}
\label{sec:orgf6277c6}
\href{http://discretemath.imp.fu-berlin.de/DMII-2018-19/}{link}
\subsection{Tutorial 1}
\label{sec:org47fff0f}
\subsubsection{Problem 2}
\label{sec:org732530c}
Each step reduces the number of components by at most \(4\). After \(5\) steps, at least \(5\) components are left. 
\subsection{Tutorial 2}
\label{sec:org040fd7b}
\subsubsection{SAT}
\label{sec:org29a4db3}
\begin{enumerate}
\item Example of un-satisfiable instance of SAT
\label{sec:org1c00cbe}
\(f(x_1) = x_1 \wedge \neg x_1\)

No matter what the instance is, this will evaluate to zero. 
\item About \(2^k\) clauses
\label{sec:orgec700f4}
We start by proving that the statement is true for exactly \(k\) variables. 

Now we induct on the number of variables, starting from \(n\). If it is true
for \(m\), then it is also true for \(m+1\) because we can replace the \$m+1\$th
variable by \(x_1\) and bang.
\item Bound being strict
\label{sec:org9bbaa8b}
For \(k\) literals, and for \(2^k\), we take all possible combinations of \(x_1,
     \cdots, x_k\) such that no two literals are the same. This is not
satisfiable. (This should evaluate to \(1\) all the time.) Because no matter
what is the value of \(x_1, \cdots, x_k\), there is a literal where the or is
zero and that literal is present in it.
\end{enumerate}
\subsubsection{Problem 1 bipartite}
\label{sec:orge3ee748}
We do a BFS. We have an array and it would be the distance. Now the claim is
that \(A(u) = A(v) \mod 2\) and if there is an edge that connects these two
vertices, then the graph is not bipartite.

We did prove that for BFS, the distances from the root are preserved.

The proof was a bit complex. But it turned out to be something about
applying BFS.
\subsubsection{Problem 3 Greedy algorithm can fail}
\label{sec:orgedbadb5}
\begin{enumerate}
\item part a
\label{sec:org3da8704}
Algorithm: Sort the edges according to the weight in ascending order. \(E =
     \emptyset\). 
\begin{enumerate}
\item No vertex of degree \(3\)
\item No cycle of length \(<\) n.
\end{enumerate}

\begin{verbatim}
          1
 +-------------------+
 | \-             -/ |
 |   \- 2     2 -/   |
 |     \-    --/     |
 |       \--/        |1
 |1      -/ \-       |
 |    --/     \-     |
 |  -/          \-   |
 |-/     1        \- |
-/------------------\+
\end{verbatim}

Another algorithm: start with an edge, something like a lightest edge. It's
vague.


\item part b
\label{sec:org95b1682}
\end{enumerate}
\subsubsection{{\bfseries\sffamily TODO} Problem 2}
\label{sec:org4cb207f}
The first \(m\) edges are the smallest weight forest.

Induction: First edge is true. Assume it's true for \(m-1\) edges are minimal
weight forest. Now kruskal adds an edge (it is the edge with smallest
weight). It does not make a cycle. We still have a forest. Now, the weight
the new is smaller than or equal to every other \(e_i\). 

Apparently it doesn't work.

But we can do the induction backwards. Suppose that it is true for \(n-1\)
upwards.

\(K_{m+1}\) is the forest that it construct in \(m+1\) steps. (This doesn't work
either.)

Apparently, we could just repeat the proof for the Kruskal.

The problem is that there could be an edge that we didn't add because it
created a cycle before. This edge can create problems later.
\begin{enumerate}
\item {\bfseries\sffamily TODO} Go again through the argument of Kruskal
\label{sec:org959e7b5}
\end{enumerate}
\subsubsection{Exercise 4}
\label{sec:orgbabe0ed}
\begin{enumerate}
\item Counter example
\label{sec:orgd0d991d}
Apparently any algorithm would fail on it because the shortest path does
not make any sense.
\begin{verbatim}
           x
           /-\
          /   \
         /     \
        /       -\
       /          \
    1 /            -\  1       
      |              \        
     /                -\      
    /                   \     
   /                     \    
  /        -2             -\  
b---------------------------\c
\end{verbatim}
\item {\bfseries\sffamily TODO} Algorithm
\label{sec:org56d4121}
\textbf{Claim}: Right after \(i\) th step of second part, \(i\) th step of second
 part, \(v \in V, \dist(v) \le \min \{ \vert w\vert \vert w \textup{
      contains } \le i \textup{ edges} \}\).

\begin{enumerate}
\item For \(i=1\), it is trivially true.
\item For \(i\ge 2\), \(v \in V\), \$w = \$ shortest path \$ \(\le\) i\$ edges. There are
parts of the argument that I skipped. \footnote{Apparently Bellman-ford is an algorithm that is better than Djistra when
it comes to negative edges. But it works for digraphs and not for directed
graphs.}
\end{enumerate}

It is not clear how the last part of the algorithm is able to detect the
negative weighted cycle. The claim more or less does it.

The time complexity is \(O(mn)\)
\end{enumerate}
\subsubsection{Exercise 5 (SAT)}
\label{sec:orgd364fbc}
\begin{enumerate}
\item Part a
\label{sec:org0157b40}
It's easy
\item Part b
\label{sec:orgff86c9f}
Write \(f(x_1, \dots, x_m) = c_1 \wedge c_2 \cdots c_m\), \(m < 2^k\).

\(c_i = \tilde{x_{i_1}} \and \tilde{x_{i_2}} \cdots\)  

for \(e\) or \(e_i\), define the set \(D_i = \{v\colon \{T, F\}^n \vert c_i(v) =
     false\}\). \(\vert D_i \vert = 2^{n-k}\), \(\sum D_i = \{v \vert f(v) = F\}\).\footnote{A lower bound for Ramsey numbers was also proved in same way. Also you
can do a probabilistic argument.}
\end{enumerate}
\subsection{Tutorial 3}
\label{sec:orgdafa4d1}
\subsubsection{Problem 1}
\label{sec:orgcd65943}
We draw the graph, and remove the edges 2, 4, 8, 12. Now there are 6 odd
number of components. There is a characterization about the maximal matching
being the minimum of \(\{n - o(G\setminus S) + \vert S\vert\colon \forall S
    \subset V(G)\}\). Now, this is \(n-2\), which means if there is a matching with
\(n-2\), it will be maximal.

Easy solution: Show that there is no maximal matching. The number of
vertices is 18. There cannot be a matching on 17, because odd. Thus, the
matching on 16 has to be the maximal matching.
\subsubsection{Problem 2}
\label{sec:org2454c55}
\begin{enumerate}
\item part a
\label{sec:orgae87802}
It is clear that \(\vert V \vert = \sum \textup{vertices in even components
     of G\S} + \sum \textup{vertices in odd components of }G\setminus S + \vert S \vert\)

The above sum \(\mod 2\) evaluates to \(\vert V \vert \mod 2= o(G\setminus S) +
     \vert S \vert\). This is same as \(\vert S \vert - o(G \setminus S \mod 2\).
\item part b
\label{sec:org2d8a796}
The idea is something like this.

For each \(S\) such that the number of odd components in the complement of
\(S\) is greater than \(S\), introduce a \(K_d\), where it's the clique on \(d\)
vertices. What should be the value chosen for \(d\)? Each value of \(d\) should
be equal to the the difference for that set \(S\).

Now this should satisfy Tutte's theorem (maybe we can do this inductively
as well.) There is a maximal matching. We need to show that in the maximal
matching contains no edge in the clique. Now, we can arrive at a matching
on the original graph \(G\) and things should be okay?

I've omitted details in the steps. 
\item part b (alternate solution)
\label{sec:org6673593}
Observation:
\begin{enumerate}
\item For all even components, there is a matching
\item For each vertex in the odd components, then \(C_o \setminus \{v\}\) has a
perfect matching.
\item If \(M\) is a maximal matching on \(G[s]\).
\end{enumerate}

Proof
\begin{enumerate}
\item Using Tutte's theorem: \(S' \subset V(e)\), \(\tilde S= S \cap S'\), then
\(\vert \tilde S\vert - o(G\setminus \tilde S)\ge \vert S \vert - o(G
        \setminus S)\) Now the LHS is equal to \(\vert S \vert + \vert S'\vert -
        o(G\setminus S) - o(Ce\setminus S) \ge 0\), now we can infer that Tutte's
theorem is satisfied inside the even components.
\item \(\vert S \vert + \vert S'' \vert - o(G \setminus S) - o(C_o \setminus
        S'') + 1\) (I missed some stuff here.)
\end{enumerate}
\end{enumerate}

\subsubsection{Problem 3}
\label{sec:org6a35a97}
\begin{enumerate}
\item Part a
\label{sec:orgefdee22}
This is kinda similar to the proof of the theorem about \(3\) regular graph
without any cut edges having a perfect matching. 

First notice that every three regular graph must have even number of
vertices.

Given \(S\) and \(G\setminus S\), we think about the the degrees of elements
inside any disconnected component of \(G \setminus S\). They cannot be \(0\)
because then, it means that there are three cut edges. They may be \(1\) and
they maybe \(2\) at most \(2\) times.

If it is \(2\) exactly 0 times, there are no cut edges and we are done (the
idea is that the sum of the degrees of each vertex have to be even, but the
degrees are either 1 or 3, so there has to be an even number of vertices.)

If it is \(2\) exactly 1 times, then there can be at most \(1\) odd component,
and \(\vert S\vert > 0\), now, Tutte's theorem!

If it is \(2\) exactly \(2\) times, then we know that \(\vert S \vert -
     o(G\setminus S)\) has to have parity same as \(\vert V\vert\), but this means
that \(\vert S\vert\) is a non-zero multiple of \(2\), and \(o(G \setminus S)\)
is exactly equal to \(2\). Now, Tutte's theorem.     
\item Part b
\label{sec:org0d536f9}
The graph from the graph theory book
\item part c
\label{sec:org66b5c17}
If \(k\) is even, we can think about a clique on \(k+1\) vertices.

If \(k\) is odd, then we can do a similar construction as \(b\).
\end{enumerate}
\subsubsection{Problem 4}
\label{sec:orgd2cfba3}
Induction on the number of vertices of the tree.

For \(2\) vertices. It has a unique perfect matching.

For \(n \ge 2\), \(n\) has to be even. There has to be at least one vertex that
is a leaf (Handshake lemma?) we picked a leaf because the edge must be in
the perfect matching. We delete the vertex right next to the edge. And on
each of the even component, we can use the induction argument? We need to
prove that if we delete a vertex inside the even component, there has to be
exactly one component is odd. 

\(\vert T' \vert = \vert T' \cap C \vert (\mod 2)\)

We can prove this. And apply induction hypothesis.
\subsubsection{Problem 4 (Alternate proof)}
\label{sec:orgbc0e45d}
\textbf{Theorem}: In any tree there exist at most \(1\) perfect matching. (the idea
 is that if there are two matching, then their symmetric difference must
 have a cycle.)
\subsubsection{Problem 5}
\label{sec:orgddb15c0}
Let \(M\) be a maximal matching on \(G\). Let \(2\alpha\) be the number of
vertices here. Let \(2\alpha'\) be the number of vertices that gets connected
in \(2\alpha'\), we are supposed to show that \(\alpha' > 1/2 \alpha\).

Let the edges in the matching be \(\{e_{i_1}, \cdots, e_{i_n}\}\). Where \(i_1
    \le \cdots, i_n\). So when the algorithm is at the step \(i_k\), either it gets
added to \(M_{t-1}\) or gets rejected. Let \(x\) number of them get's rejected
and \(y\) number of them gets added.

When does an edge gets rejected? If one of the vertex in \(e_{i_k}\) is
already in \(M_{t}\). Let us now count the number of vertices in \(M_t\) at the
end.

\(M_t \ge x + 2y \ge x+y = (\alpha)\).

Strictness: Consider the following graph and ordering of vertices:
\begin{verbatim}
o----------------o----------------o----------------o
       e2              e1                 e3       
\end{verbatim}

The maximal matching is \(\{e2, e_3\}\), whereas the algorithm generates
\(\{e_1\}\).
\subsection{Tutorial 4}
\label{sec:org7cfc530}
\subsubsection{Problem 1}
\label{sec:org2ba63be}
The inequality is super easy and just follows from the definition.

The proof is equality is also very easy. If no permutation satisfy the
condition, then we can easily prove that there cannot be an equality.
\subsubsection{Problem 2}
\label{sec:orge054cd8}
We can take the negative of all weights. And apply Hungarian algorithm.
\subsubsection{Problem 3}
\label{sec:orgc7fc623}
Step \(i\) of the algorithm: let \(M\) be the maximum matching in the equality
graph \(G_{u, v}\) and \(\vert r \vert < n\) and let \(Q\) be the vertex cover
provided by the algorithm, then \(T = Q \cap Y\) and \(R = Q \cap X\) and
\(\varepsilon = \min \{u_i + v_j - w_{ij}\vert x_i \in X \setminus R, y \in Y
    \setminus T\}\)

Let \((\bar u, \bar v)\) be the weighted cover after calculating with
\(\varepsilon\).

We need to show that \(\vert X \setminus R \vert > \vert T \vert\). This is
true, because if it is not true, then we have that \(n = \vert R \vert +
    \vert X \setminus R \vert \le \vert R \vert + \vert T \vert = \vert Q \vert
    = \vert r \vert < n\).

Indeed at each step, the cost function decreases by some number.

Why does the algorithm terminate? 

\(w_{ij} = \frac{p_{ij}}{q_{ij}}\), and \(q = LCM(p_{ij}, q_{ij})\), then
\(\epsilon \ge 1/\varepsilon\), then we can always finish the algorithm.

Or we can make all the weights as integers. The rational case follows
easily.
\subsubsection{Problem 4}
\label{sec:orgf691e5e}
Questions: 
\begin{enumerate}
\item Is this the unique extremal examples? The answer is yes.
\item What are the extremal examples?
\item Hypergraphs: \(k\) uniform Hypergraphs. We can define the notion of perfect
matching in Hypergraphs. What is the maximum number? A paper in 2011
solved it.
\end{enumerate}
\subsubsection{Problem 5}
\label{sec:orgebfb587}
Isn't this kinda simple? Like it is trivial when \(n \ge k+2\), when \(n= k+1\),
the sum on the RHS evaluates to \(k -1/2\), since \(k\) is an integer,
\(\delta(G)\) has to be at least \(k\).
\subsubsection{Problem 5 (proof)}
\label{sec:org3326f1a}
What is the definition of \(k\) connected? 

\(\kappa(G) \ge k \iff G\) is \(k\) connected.

\(G, n \ge k+1\), \(\delta(G?) \ge \frac{n+k-2}{2}\). It is sufficient to show
that if we subtract a set of size \(k-1\), then the graph is connected.
\(G[V(G)\setminus S]\) are either neighbours (in this case it's trivial.)

\(u, v \in V(G')\). 

\begin{enumerate}
\item \(u \in N(v)\), then we are done.
\item \(N(v) \cap N(u) \neq \empty\). Suppose \(N_G'(v) \cap N_G'(u) = \emptyset\).
\(n+k-2 - 2(k-1) = n-k\), we should have so much vertices in \(G'\) for the
condition to be true. But \(G'\) has \(n-k+1\) vertices.
\item Remark: \(\delta \ge (n-1)/2\), then the graph is 1-connected or connected.
Whereas, if \(\delta \ge n/2\), then the graph has a hamiltonian cycle.
\end{enumerate}
\subsubsection{Problem 5 (Bonus)}
\label{sec:org82372dc}
An example where the bound in sharp.
\subsection{Tutorial 5}
\label{sec:org71ae1fe}
\subsubsection{Problem 4}
\label{sec:orga7f77b0}
We can do this in cases. 

\begin{enumerate}
\item \(\kappa(G) = 3\), then because \(\kappa \le \kappa' \le 3\), \(\kappa' =
       \kappa = 3\).
\item \(\kappa = 1\), then disconnecting one vertex would disconnect the graph.
Let \(U_1\), \(U_2\), \(U_3\), be the at most three components that would
\end{enumerate}
\subsection{Tutorial 6}
\label{sec:org447cc9a}
\subsubsection{Problem 1}
\label{sec:orgf87f97f}
It is easy to see that \(\kappa = 2\). It is easy to see that \(\kappa' \le 4\).
We need to see how to ignore the other parts.

We find two hamiltonian cycles and then two of the edges have to be on the
hamiltonian cycle. And the third edge cannot really disconnect the graph.
Remove the Hamiltonian cycles, then graph still has \(\kappa' 2\). Thus the
original graph has \(\kappa' = 4\).

\textbf{Hint}: Let \(S\) be an edge cut of size \(\le 3\). Then we need to show \(S \ge
    5\), and \(\vert \bar{S}\vert \ge 5\). Then the induced graph has to be \(K_5\). But
there is no \(K_5\).
\subsubsection{Problem 3}
\label{sec:org41667e0}
\(K_n\), \(n\) is a natural number that is very large. There were two \(K_n\) at
both the end and in the center a graph of size \(k\).
\subsubsection{Problem 3}
\label{sec:org8d60665}
\begin{enumerate}
\item \(k=d=k'\), \(K_{d+1}\) would do
\item \(k < d\) and \(k'\) two \(K_{d+1}\) graphs and do connections between them
\end{enumerate}
\subsubsection{Problem 4}
\label{sec:org7b3bbb1}
Something like if \(\kappa' = r\), then there are \(r\) edge disjoint paths. If
\(\kappa < \kappa'\), then there is a point in the edge disjoint path that
doesn't blah blah.

For proving for Peterson graph: there is a theorem by Brouwer that proves
this.

A simple way to do it is that remove a vertex and we get a graph that has a
hamiltonian cycle.

\(\vert S, \vert{S} \vert = \sum d(v) - 2e(G[S])\)\footnote{If there is an edge cut of size \(2\), then there is a triangle in the
peterson graph.}
\subsubsection{Problem 5}
\label{sec:orgafb4457}
You make a line graph and then argue that the \(\kappa'\) of the graph is same
as the \(\kappa\) of the line graph. (There is an intermediate graph which
should be formed by adding extra vertices \(u\) and \(v\), and the edge \(ux\) and
\(yx\).)

"Vertex transitive" graph. Any two vertices are the same in Peterson graph.

Called the Harrary graph.
\subsubsection{Problem 6}
\label{sec:orgdbb488e}
\(\val(f) = f^-(t) - f^{+}(t) = \sum_{u \in \bar{S}} (f^{-1}(w) - f^{+}(w)) =
    \sum_{u\in \bar{S}}(\sum_{v \in V} f(vu) - \sum_{v \in V} f(uv))\) some
calculations and we are done.
\end{document}