#+TITLE: Discrete Math II 
#+author: Hari
#+LATEX_HEADER: \usepackage[left=2cm, right=2cm, bottom=2cm, top=2cm]{geometry}
#+LATEX_HEADER: \usepackage{parskip}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amssymb}
#+LATEX_HEADER: \def\R{\mathbb{R}}
#+LATEX_HEADER: \def\Z{\mathbb{Z}}
#+LATEX_HEADER: \def\N{\mathbb{N}}
#+LATEX_HEADER: \def\max{\operatorname{max}}
#+LATEX_HEADER: \def\P{\textup{P}}
#+LATEX_HEADER: \def\NP{\textup{NP}}
#+LATEX_HEADER: \def\coNP{\textup{co-NP}}
#+LATEX_HEADER: \def\min{\operatorname{min}}
#+LATEX_HEADER: \def\dist{\operatorname{dist}}
#+LATEX_HEADER: \def\prev{\operatorname{prev}}
#+LATEX_HEADER: \def\pos{\operatorname{pos}}
#+LATEX_HEADER: \def\conv{\operatorname{Conv}}
#+LATEX_HEADER: \usepackage[T1]{fontenc}

* Lecture 2<2018-10-17 Wed>

** Review
*** Random stuff about algorithms
    Algorithm A

    Input class I

    $T(A, I)$: time algorithm $A$, input $I$.

    The worst case time complexity of $A$ on $I$ is $\max_{I\in \mathbb{I}} (A, I) = T_(n)$.

    The worst case complexity of $I = \min_{A} T_A(n) = T_{I}(n)$. A function that grows with $n$.

    Average case complexity $\mathbb{E}(T(A, I))$.
*** Sorting
    Sorting algorithm $A$, $T(A, \pi) =$ number of comparisons that $A$ makes to find $\pi.$

    Yesterday, we proved that for insertion sort (the stupid algorithm), the
    worst case running time was $\binom{n}{2}$.

    Binary insertion:  $T(n) \le n log_2{n}$.

    Merges sort: $T_M(n) =le n\log_2{n}.$
*** Theorem about lower-bound of sorting
    If $A$ is a sorting algorithm (correctly sort $n$ numbers)

    Then $T_A(n) \ge \log_2(n!)$.

    In particular, using the stirling's formula, $T_A(n) \ge n\log_n$.
**** Proof
     The algorithm runs on the permutations on the set of $n$ numbers. Define
     $\forall \kappa \in \N$ blah blah.

     $S_n \subset S_n{\alpha, \kappa} = \{\pi \in S_n \colon \textup{where A
     receives input $\pi$ there, it receives $\alpha$ as the sequence of the
     list of first $k$ answerers}\}$
**** Observation
     Everything is determined if we run it.

     $S^n_(\alpha, k) \cap S^n_{\beta, k} = \emptyset \forall \alpha \neq \beta$

     $\cap S^{n}_{\alpha, k} = S_n$

     Suppose, $T_A(n) < \log_2(n!)$.

     $S_n = \cap S^n_{\alpha, k}$ partition into $2^k$ sets.

     $2^k < n!$ implies that there exist $\beta$ such that there exist $\pi_1
     \neq \pi_2 \in S_{\beta, r}$.

     Run $A$ on $\pi_1$, we receive the answers $\beta$ implies that $A$ outputs
     $\pi^{*} \in S_n$

     + Case 1: $\pi^* \neq \pi_1$, a contradiction to the correctness of $A$.

     + Case 2: $\pi = \pi_1$. Run $A$ on $\pi_2$ implies $\beta$ is the answer.
       $A$ outputs $\pi_{*}$, this is a contradiction that $\pi_{*} \neq \pi_2$.
       Contradicts the correctness of $A$.

       Called the *information theoretical lower bound*.
** Graph algorithms
*** Connectedness of graph
    A graph $G$ is connected if for every two vertices $u$ and $v$, there exists
    a $uv$ path in $G$.

    This induces an *equivalence* relation where $u$ is equivalent to $v$ if
    there exists a path that connects $u$ and $v$. Create equivalence classes,
    which are called the *connected components* of $G$.

    Observation: There is no edge between different connected components.
*** How do you decide whether a graph is connected?
    Take a vertex $v$. We maintain a list of all vertices that are visited. We
    redo the same thing for every other vertex. We repeat this until we saw all
    the vertices in the graph.

    Algorithm (Comp (V))
    #+BEGIN_VERSE
    Initialize: Queue Q = v; and W = empty
    for all $i \ge 1$
    step i: v_i first vertex in Queue.
    remove v_i from the queue  and put it in W
    put all of $N(v_i) \setminus W$ into $Q$.

    IF Q = \empty, STOP and return $W$ as the connected component of $v$.
    else go to step i+1
    #+END_VERSE
*** Theorem: Comp(v) returns $C_G(v)$
    Suppose $u \in C_G(v) \cap W_{out}$.

    Let $P$ be a vu path in $G$.

    Comp(v) puts a vertex into $w$ only if all its neighbours are put into $Q$.
    We stop only if $Q$ is empty. Also $v_f$ was in $Q$ at some point $A$. $v_f$
    had to be moved to $w$. This is a contradiction.

    Other direction: $u\in W_{out}$. Before $u$ became part of $W$, $u$ was in
    $Q$. Why? Because there is a $u_1 \in Q$, $u \in N(u_1) \setminus W$.
    (More things, I skipped.)
*** Spanning tree
    Suppose we run Comp(v) on a connected graph, where a vertex $w$ is put into
    $Q$, then there is a unique edge coming with it that attaches it to $v$.
    (the vertex that is moved from $Q$ to $W$ at the same time.)
*** Theorem about spanning tree
    The following are equivalent: for an $n$ vertex graph.

    1. T is a tree (connected, acyclic.)
    2. T is connected and has $n-1$ edges.
    3. T is acyclic and has $n-1$ edges.
    4. For every pair of vertices $u$ and $v$ in $V(T)$, there is a unique $uv$
       path.
**** Definition (spanning tree)
     $T \subset G$ is a spanning tree if $T$ is a tree and $V(T) = V(G)$.
*** Special spanning trees
    Let $G$ be connected and run Comp(v) (don't forget the edges.)

    /What if/ we always put $N(v_i) \setminus W$ to the top of $Q$. (We call
    this the *depth first search* tree.) This is going to create a tree which is
    long (?)

    /What if/ if we put it to the bottom of the tree, this will create a
    *breadth first search*. You will create which is short.

    A diagram that I ignored.
** Minimal spanning tree
   Given a graph $G$. (can be a complete or arbitrary graph.)

   We have a weight function that is assumed on the edge set to $\mathbb{R}$.
   What we want is a spanning tree $T\subset G$ such that the cost of the sum of
   weights on the edges is minimum (i.e., for any other spanning tree, the sum
   of the weights on the edges would be more than the current one.)
*** Naive algorithm
    There is at most $n^{n-2}$ (Cayley's theorem.) spanning trees on $n$ vertices. Let's look at all
    of them and calculate the weights and output the minimum.
*** Kruskal's algorithm
**** Step 1
     Sort edges in increasing order of weights $e_1, \cdots e_m$ such that
     $w(e_1) \le w(e_n) \le \cdots, \le w(e_n)$.

     Start with an empty forest $E(F) \neq \emptyset$ for all $v \in V$, $c_v = v$.
**** Step 2
     For each edge $e_i = uv$. For $\forall i \ge 1$, if the forest plus the new
     edge has a cycle, then $C_v$ remains the same.

     If there is no cycle, we have a new forest, i.e., the bigger forest with
     the extra edge added to it.
**** The end
     Output $F$.
*** Theorem: Kruskal's algorithm returns the min-weight spanning tree.
    Proved in discrete Math 1. 
*** Running time of Kruskal
    The first step involves sorting. This can be done in $O(|E| \log|E|)$.

    There is $O(m)$ and $O(n^2)$. 

    If $G$ is dense, then $O(m\log m)$ and if $G$ is sparse, then $O(n^2)$.
* Lecture 3 <2018-10-23 Tue>
** Spanning trees
   Another perspective: get to one place to another in the fastest way possible.
   Versus the minimum spanning tree. [fn:1]
** Problem
   Given graph $G=(V, E)$, a distance for $d\colon E \rightarrow \mathbb{R}_{\ge 0}$. 

   *Goal*: Given a vertex $u\in V$, find the shortest path to any vertex $v \in V$. 

   The brute force way is to find all the path and find the minimu. 
** Idea
   Maintain a set of vertices to where a shortest path from $u$ was found. And
   in each step we add one vertex to $W$.

   *Key observation*: If $P$ is a shortest $uv$ path, then for every $w$ on this
    path, $P[u, w]$, this is also the shortest path. ($P[u, w]$ represents the
    path from $u$ to $w$ through $P$.)
** Dijkstra's algorithm
   *Input* is a graph $G = (V, E)$ which is connected. [fn:2] We have a distance
   $d\colon E \rightarrow \mathbb{R}_{\ge 0}$.

   *Output*: For every vertex $u \in V$, the distance from $u$ and also a
   shortest path.
*** Algorithm
    *Initialization*: dist[u] = 0

    For every other vertex $v$, I set $d[v] = \infty$. $prev[v] =
    \textup{null}$. Maintain the set $W = \emptyset$. 

    *Iteration*: Choose a vertex $v_0 = \min\{\dist[v]\colon v  \in V \setminus W\}$

    Update $W = W \cap \{v_0\}$.

    $\forall v \in V \setminus W$ if $\dist[v] > \dist[v_0] + d(v_0, v)$
    then $\dist[v] = \dist[v_0] + d(v_0, v)$ and $\prev[v] = v_0$. 

    *Termination*: If $W = V$, then STOP and output $\dist[v]$ search head of
    $\prev$ for a $uv$ path.

    An example was done. [[https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm][Wikipedia]]. 
*** Analysis 
**** Correctness 
     *Claim*: At the time $v_0$ is put into $W$, $\dist[v_0]$ is the distance of
      $v_0$ to $u$. 

      (This would prove the correctness, because $dist$ does not change after
      vertex is in $W$.)

      Proof: Induction on $\vert W\vert$.

      Because $\vert w \vert = 0$ $u$ is put into $W$, $\dist[u] = 0 = d(uu)$. 

      Suppose $\vert W \vert \ge 1$, we put $v_0$ into $W$. If this is the case,
      then $\dist[v_0] = \min\{\dist[v_0]\colon v \in V \setminus W\}$.

      Suppose $\dist[v_0] > s(uv_0)$. (here $s$ is the shortest path going
      from one vertex to another.)

      Take the shortest $uv_0$ path $P$. There will be a first vertex on $P$ not
      in $W$, call it $v_f$ and $v_p$ be its predecessor. $\dist[v_0] > s(uv_0)
      = s(uv_f) + s(v_fv_0) \ge s(uv_f) = s(uv_p) + s(v_pv_f) = dist[v_p] +
      d(v_pv_f)$. (By our observation from before, both these paths are the
      shortest.)

      When we are updating after putting $v_p$ into $W$, we consider $v_f$ and
      we will put it in $W$. This is a contradiction. 
**** Termination
     In each iterating step, one vertex is put into $W$ and stays there and then
     in $n$ iterations, we are done. 
**** Cost
     Finding $v_0$, then $O(\vert V \vert)$.

     Adding $v_0$ to $W$ is $O(1)$
     
     Updating $\dist$,  $O(\vert V\vert)$.

     With better data structure $O(\vert E\vert + \vert V \vert log \vert V \vert)$.
** Euro 2020 or Travelling Salesman Problem
    Watch a game in every one of $13$ cities. We want to visit all $13$ but as
    cheap as possible. The English football fans cannot return to the same
    country. A $13$ vertex graph, between any two vertices, there is a price of
    the air ticket.

    We are looking for a Hamilton cycle.

    Given graph $G = (V, E)$ and $w\colon E \rightarrow \R_{\ge 0}$. A cycle
    that does not repeat.
** Complexity classes
   $\P$, polynomial time running problem. 

   |    $n$ | $1000n$  | $1000n\log n$ | $10n^2$    | $2^n$           | $n!$            |
   |--------+----------+---------------+------------+-----------------+-----------------|
   |     10 | 0.01 sec | 0.0002 sec    | 0.001      | 0.0000001 sec   | 0.003 sec       |
   |    100 | 0.1 sec  | 0.001 sec     | 000001 sec | 400000 years    | $>10^100$ years |
   | 100000 | 17 min   | 20 sec        | 2450 min   | $>10^100$ years |                 |
* Lecture 4 <2018-10-24 Wed>
** Decision problems
   Problems that output yes or no
*** Example
    - Is there a spanning tree of weight $\le 42$. (Kruskal algorithm.)
    - Is there a path of weight $\le 405$ from $u$ to $v$? (Djistra's algorithm.)    
** Class P
   The set of all decision problems with a polynomial time algorithm. 
** Traveling salesman problem
   We don't know if the problem is in $\P$. 

   As a decision problem: There is a graph $G = (V, E)$ and $w\colon E
   \rightarrow \R_{\ge 0}$., You ask what is the smallest weight Hamiltonian cycle. [fn:3]
*** Approximation algorithm
    *Definition*: An $\alpha$ approximation of TSP is an algorithm that turns a
     Hamiltonian cycle whose weight is within $\alpha$-fraction of the min
     weight Hamiltonian cycle.[fn:4]
*** Extra conditions
    Triangle inequality: the weight function satisfies the triangle inequality
    if every two vertices of the graph, the weight $w(xy) \le w(xz) + w(zy)$.

    Examples: The usual Euclidean distance satisfies this. 
    A non-example is Airfare cost.
** Approximation algorithm for TSP
*** Algorithm
    *Input*: a weight function $w\colon E(K_n) \rightarrow \R_{\ge 0}$ with
    triangle inequality. (We assume that it is a complete graph.)

    *Output*: Hamiltonian cycle $C$.

    *Algorithm*:
    1. Find the minimum weight spanning tree (Kruskal algorithm.)
    2. From the spanning tree, we create a closed walk spanning all vertices by
       traversing each edge of $T$ twice in both directions.
    3. Traverse $W$, when hitting a vertex that was used before, we do a short
       cut. (Go instead to next vertex $W$) Do this iteratively. 
    4 *Termination*: when all vertices are traversed, output $C$. 

    We know that $w(W) = 2w(T)$ and $w(C) \ge w(W)$. 

    $C^{*}$ is a minimum weight Hamilton cycle. How does this compare to the
    weight of the spanning tree. We know that $w(C^{*}) \ge w(T)$. and thus
    $w(C) \le 2 w(C^{*})$.
*** Running time
    1. Kruskal: $O(n^2\log n)$
    2. Closed walk $W$, $O(n)$.
    3. short cutting: $O(n)$. 
** Hall's theorem
   If $G = (A \cap B, E)$ a bipartite graph, then $G$ has a matching $A$ if and
   only if for every subset $S \subset A$, $\vert N(S) \vert \ge \vert S \vert$.

   The non-trivial direction implies that when there is no matching saturating
   $A$, then there is an $S \subset A$, $\vert N(S) \vert < \vert S \vert$.
** Class $\NP$
   A decision problem is in class $\NP$ if the YES answer can be verified
   efficiently (within time that is polynomial in variable size.) (In other
   words, there is a polynomial size certificate.)

   The perfect matching problem is in NP. [fn:5]

   Opposite of perfect matching: Does $G$ has a $PM$? We can use Hall's
   condition as a certificate. Hence the problem is in NP.
** Class $\coNP$
   Means that the problem is in $NP$ and the negation of the problem is also in
   $NP$.
** About Hamilton path
   The Hamilton path problem is in $NP$. 

   But the negation of the HAM is not known to be in $NP$. In other words, we
   don't know if HAM is $\coNP$.[fn:6]
** Problem reduction
   Maximum weight spanning tree problem can be reduced to a minimum weight
   spanning tree. (You can solve the minimum weight spanning tree problem by
   inverting the sign of the edges.) Furthermore, it is a polynomial time
   reduction.

   A problem is called $\NP$ hard if any problem in $\NP$ class can be reduced
   by the problem.

   If furthermore, the problem is in $\NP$, then we call it $\NP$-complete.

   Example: 3-SAT is $\NP$ hard and also $\NP$-complete. 

   Karp came up with $21$ natural $\NP$-complete problems, all of them are $\NP$
   complete.
* Lecture 5 <2018-10-30 Tue>
** NP class
   A yes/no problem is in class NP if the answer yes can be verified
   efficiently.
*** Examples
    1. Does the bipartite graph have a perfect matching.
    2. Does the bipartite graph have no perfect matching.
    3. Does the graph have a Hamiltonian-cycle? 
    4. *Don't know* Whether a problem have no hamiltonian cycle.
** P class
   A yes/no decision problem is in P if the answer can be found in polynomial
   time. It is obviously true that $P \subset NP$.
** Co-NP
   A yes/no problem is in the class Co-NP if the no-answer can be verified
   efficiently. Again trivially, $P \subset NP \cap no-NP$.
*** Example of NP intersection co-NP
    1. Perfect matching problem in bipartite graph is in the intersection.
    2. Is this graph 2-colorable. 
    3. Is this graph Eulerian?[fn:7] Verify that the degree of each vertex is even.
       (polynomial time algorithm.) Another answer: The yes answer is the list
       of edges in an Eulerian edges. For the NO answer, we will be given a
       vertex of odd-degree.
** Conjecture P $\neq$ NP
** Stronger conjecture of $P \neq$ $NP$ intersection $co-NP$
   Is there a factor of $n < k$. This problem is in the intersection of NP and
   co-NP.

   Is $n$ a prime. This was also a problem. But in 2002, it was proven to be
   true. (The input size is in $\log n$.)

   A problem in $NP$ and co-NP and then trying to find a good characterization
   and then solving the problem.
** NP completeness
   Subtle difference between easy and hard problem.
   1. The graph is 2-colorable? is in P[fn:8]
   2. Is the graph 3-colorable? is in NP-complete.
   3. Is this planar graph 3-colorable? is in NP-complete.
   4. Is this planar graph 4-colorable? is in P. (The is in complexity class TRIVIAL)
      The answer is always yes.
** Hall's theorem
   If you have a graph $G$ that is bipartite, then $G$ has a perfect matching if
   and only if for every $S$ inside $A$, the $\vert N(S) \vert \ge \vert S
   \vert$ and for every $S \subset B$.
** Necessary conditions for Hamiltonianity
   Dirac's theorem $d(G) \ge n/2 \implies G$ is hamiltonian. [[https://en.wikipedia.org/wiki/Hamiltonian_path#Bondy%E2%80%93Chv%C3%A1tal_theorem][Wikipedia]] (This is
   a sufficient condition.) For a cycle, this fails.   

   Proposition: If a graph $G$ is hamiltonian then $\forall S \subset V(G)$,
   $C(G\setminus S) \subset \vert S \vert$. (This is a necessary condition.)[fn:9] [fn:10]

   A simple example is an edge. It's probably also true for Peterson graph.

   We can try to frame something like if $t C(G\setminus S) \subset \vert S
   \vert$. For peterson graph $t = 4/3$. There is a conjecture on if we can talk
   about a value of $t$ and do stuff.
** Does a graph have a perfect matching? Tutte's theorem
   The question is whether this is in NP intersection co-NP. 

   The hall's theorem was for bipartite graph.

   Consider $K_{2k+1}$. It has all the edges, but has no perfect matching. Odd
   (vertices) graphs are bad obviously.

   There was something about applying the necessary condition for Hamiltonian
   cycle to the matching problem and arriving at a necessary condition (and sufficient condition.)

   $G$ has a perfect matching $\implies$ $\forall S \subset V(S)$, $o(G
   \setminus S) \subset |S|$.[fn:11]

   *Proof*: Let $M$ be a perfect matching in $G$. In each odd component, there
   is at least one edge $e_L \in M$ which has one vertex in $b$ and the other in
   $S$. These edge $e_L$ are disjoint $\implies$ [fn:12] [fn:13]
** Proof of Tutte's theorem
   Let $G$ be a counter example with maximum number of edges.[fn:14]

   What is a counter example? It should satisfy the following properties:
   1. $G$ has no perfect matching
   2. $\forall S \subset V(G)$, $o(G \setminus S) \le \vert S \vert$

   Add $xy$ to $G$ and $G+xy$ is not a counter example. We claim that $\forall S
   \subset V(G)$, $o((G+xy)\setminus S) \le \vert S \vert$. [fn:15]

   I know that $o(G\setminus S) \le \vert S \vert$.
   - If $xy \in S = \emptyset \implies \vert S \vert$ does not decrease.
   - If $xy$ goes between even components, then nothing changes.
   - If $xy$ goes to an odd components, the number of odd components decreases.
     Basically do a case analysis and it checks out.

   $U = \{v \in V(G) \colon d(v) = n- 1\}$
   
   Case 1. $G \setminus U$ is the disjoint union of cliques. There are even
   cliques and odd cliques. Even cliques can be matching within themselves. In
   odd cliques, you match everything but one, but we can match the extra vertex
   to $U$. Now what happens with the vertices inside $U$ that doesn't get a pair
   in $U$. If that part is odd, then the whole thing is not odd. But it is not
   odd, because we have a contradiction when we put $S = \emptyset$. So after
   everything, the number of unmatched vertices is even (otherwise we have a
   contradiction.)

   Case 2. $G \setminus U$ is not a disjoint union of cliques. The idea is from
   two almost perfect matching of $G$, create a perfect matching of $G$ and two
   more edges, create a perfect matching. This leads to a contradiction. 

   Claim: In $G, \exists x, u, v, w$ such that $xu, xv, \in E$, $uv, vw \notin
   V(G)$. $w$ is anything that is not in the neighbourhod of $x$ which is non
   empty.[fn:16]

   #+BEGIN_SRC artist
  
                        x .--------------------------- w
                         /.
                        /  -\                           
                      -/     \                          
                     /        -\                        
                    /           -\                      
                  -/              \                     
                 /                 -\                   
                /                    \                  
               /                      -\                
             -/                         \               
            /                            -\             
           /                               -\           
         -/                                  \          
        /                                     -\        
     u .----------------------------------------. v
                     
                     
   #+END_SRC
* Lecture 6 <2018-10-31 Wed>
** TODO Tutte's theorem proof
   $\leftimplies$ $G$, a counter example with maximum number of edges.

   *Claim*: $G+xy$ has a p.m. $xy\in E(G)$, $G$ has no p.m., $\forall S \in
    V(G)$, $o(G \setminus S) \le o(\vert S \vert)$

    $U = \{v \colon deg(v) = n-1\}$ and $n=\vert V(G)\vert$.

    Case 1: $G \setminus U$ is the union of cliques. We are done, we use Tutte's
    condition for empty set. 

    Case 2: Otherwise, there exists the diagram that I already drew. Our claim
    implies that there exists a perfect matching $M_1$ in $G + xw$ and also
    there is a perfect matching in $G$ if one adds $uv$. Our goal is to find a
    perfect matching in $M_1 \cap M_2$. Our goal is to find a perfect matching
    in $M_1 \cap M_2 \setminus \{xw, uv\} \cap \{ux, xv\} \subset E(G)$.

    $M_1 \cap M_2$ is the disjoint union of $K_2$s and even cycles[fn:19]. The degree
    of each vertex in the union is either $1$ or $2$, because the matching is
    perfect because there are two of them. If there is one, then the vertex
    participates in the same edge with () matching $\implies$ $K_2$ component.

    If it is $2$ $\implies$ vertex participates in a cycle component.

    (cycle is even since edges of the matchings alternate.)

    There was a diagram and the proof involved doing stuff on the diagrams. I
    don't understand what he did.

    The proof in the class was from bondy and murthy. [[http://www.zib.de/groetschel/teaching/WS1314/BondyMurtyGTWA.pdf][Bondy and murthy]] page 76. 

    The wikipedia link seems to have the same proof.
** Perfect matching is in NP intersection co-NP
   Tutte's theorem tells us that the problem is in the intersection of NP and
   co-NP. The certificate for the yes case is a matching and for the No case is
   a case where the Tutte's theorem is false.

   The problem is also in P.
** Corollary to hall theorem (Theorem of Frobenius)
   A $k$-regular bipartite graph has perfect matching.[fn:20] (1-factor)

   A $k$-factor is a spanning $k$-regular subgraph. 

   This is not true for general graphs. Example: odd cycles, they are $2$
   regular and 1-factor. Are there examples with even number of vertices.
   (3-regular graph with no $1$ factor.)
   
   
** Theorem (peterson)
   A $2k$ regular subgraph has a $2$-factor. 
** Theorem (another peterson theorem)
   Every $3$-regular graph without cut edges[fn:21] has a perfect matching. (Theorem in
   Bondy and Murthy) [fn:22]
*** Proof
    The proof is component wise. Now we assume that $G$ is connected.

    We will check that Tutte's condition holds. Then Tutte's theorem tells us
    that $G$ has a perfect matching.

    $S$ be an arbitrary subset.

    Consider the number of edges between odd components and $S$.

    Claim: For every odd component, there is at least three edges going to $S$
    from $C$.

    Proof:
    1. $0$ edges is not possible because connected. 
    2. $1$ edge is
       not possible, because it would be a cut edge. 
    3. $2$ edges are not possible
       because the sum of the degrees of the vertices inside the component -2,
       $\sum d(v) - 2 = 2 \cdot e(C)$. Now this is just a handshake lemma.[fn:23]

    The number of edges between odd components and $S$. The number of edges
    going is at least $3$ times the odd components. On the other hand, the
    number of components cannot be more than $3 \vert S \vert$.

    $$ 3\cdot o(G \setminus S) \le \textup{number of edges between odd components and S } \le 3 \cdot \vert S \vert$$

    Thus $\cdot o(G \setminus S) \le \vert S \vert$
** Maximum matching problem
   In the decision problem formulation. Is there a matching of size $k$ in the
   graph on $n$ vertices.

   Is this problem in NP intersection co-NP? The problem is obviously in NP. 

   For Bipartite graphs, we can provide the other verification by Konig's
   theorem.
** Konig's theorem
   $G$ is bipartite, then $\alpha(G)=\beta(G)$. Here $\alpha$ is the size of the
   largest matching and $\beta$ is the size of smallest vertex cover.

   $C \subset V(G)$, the vertex cover if $\forall e \in E(G)$, $e\cap C \neq
   \emptyset$.
** Konigs on Maximal matching problem
   Suppose $\alpha(G) = 88$, then konig gives a certificate to show that there
   exists a vertex cover of size $88$. So this means that there are no matching
   of size more than $89$.
** Homework: a corollary of Tutt due to Berge
   If $G$ is a arbitrary graph, then it is true that $2\alpha'(G)$ is equal to
   the minimum of the following sum of quantities: $\min \{ n - o(G\setminus
   S) + \vert S \vert \colon S \subset V(G) \}$.[fn:24]

   It is easy to show one direction. But this is the maximum size, which is the homework.

   This example would put the problem of maximum matching into the intersection.
** How to find maximum matchings in polynomial time?
** Proposition about maximum matching
   IF $M \subset E(G)$ is a maximum matching of $G$, $\iff$ there is no
   $M$-augmenting path.

   $M$-augmenting path: It's a path in which non-edges and edges follow each
   other alternatively. One direction is easy. If $M$ is a maximum matching,
   then there is no $M$ augmenting path.
** A M alternating path
   A path of $G$ where edges of $M$ alternate with non-edges of $m$.

   An $M$-alternating path that starts and ends in an unsaturated vertex is
   called $M$ augmenting. [[https://en.wikipedia.org/wiki/Saturation_(graph_theory)][Wikipedia]]
** Using the characterization for Bipartite graph
   [fn:25] You have a matchin and then unsaturated vertices. The idea is to
   somehow extend the matching to the unsaturated edges.

   #+BEGIN_SRC artist
     -------------------------------------------------------------\------------------------------\---------------
     -                                                                                                           \------
     (                                                                                                                  )
     \              |           |              |              .                                                  /------
     \              |           |              |                            .                    /---------------
     \              |           |              |                  /------------------------------
     ---------------------------+--------------+------------------
                     |          |              |
                     |           \              \
                     |           |              |
                      \          |            --+----------------------------------------------------------------------------------------------------------------------
            ----------+----------+-----------/  |                                                                                                                      \---------------------------------
     ------/          |          |             .|                 .           .     .       .                                                                                                            \------------
     (                           |                                                                                                                                                                                    )
     ------\                                                                                                                                                                                             /------------
            ---------------------------------\                                                                                                                         /---------------------------------
                                              -------------------------------------------------------------------------------------------------------------------------



   #+END_SRC
* Lecture 7 <2018-11-06 Tue>
** Maximum matching is in P 
*** Proposition
    $M \subset E(G)$ is a matching in $G$.

    $M$ is a maximum $\iff$ there is no $M$-augmenting path in $G$. (is
    $M$-alternating if it starts and ends at an unsaturated vertex.)
*** Augmenting path algorithm
    Input: Bipartite graph $G = (X \cap Y, E)$, a matching $M \subset E$.
    Output: Either an $M$-augmenting path or a cover of size $\vert M \vert$.

    Initialization: $S = U$, $Q = \emptyset$, $T = \emptyset$

    Iteration: If $Q = S$ STOP and return $M$ (as maximal matching), $TU(x
    \setminus S)$ (as min cover of size $\vert M \vert$) Else select $x \in S
    \setminus Q$, $\forall y \in N(x)$ with $xy\in M$, DO if $y$ is unsaturated,
    then stop return a $M$-augmenting path from $U$ to $y$. Else $\exists w \in
    X$, $yw \in M$ update, $T = T \cap \{y\}$ and $S = S \cup \{w\}$. Update $Q
    = Q \cup \{x\}$. [fn:26]
*** Proposition
    $G$ graph, $M \subset E(G)$ is a matching. $C \subset V(G) \implis \vert M
    \vert \le \vert C \vert$. Here $C$ is the cover.

    The idea is that every cover has to be bigger than the matching.
*** TODO Proof of correctness
    Stopping the algorithm: The algorithm can either stop with a $M$-augmenting
    path or it can stop with a maximum matching or a cover.

    Proof of correctness: If the algorithm terminates with a matching $M$ and a
    cover $T \cap (X \setmius S)$, we terminate at $Q = S$, which means that we
    have explored all the neighbours of $S$ and they are all in $T$. We want to
    conclude that there exists no edge between $S$ and $Y-T$. (Because if there
    is no edge between $T$ and $Y-T$, then $T$ together $S-T$ is a cover.)

    If there is an edge from $S$ to an unsaturated vertex $y \in T$, then we
    would have immediately put this vertex into $T$. These two cases are not
    possible.
*** Comments
    $\vert M \vert = \vert T \vert + \vert X \setminus S\vert$. By the selection
    of $S$ and $T$, vertices of $T$ are put into $T$ where their $M$-partner is
    put into $S$.

    $\implies$, $S = U \cap M$ partners of vertices in $T$.
** Theorem
    Repeatedly applying APA to bipartite graph produces a maximal matching and
    minimal cover. The running time is $O(V(G) \cdot e(G))$

    If we repeat APA $\le n/2$ times. One running of APA considers each edge
    $\le 1$, implies $O(e(G))$.
** Matching with weights
   We have a weight function on the edges. $w\colon E(K_{n, n}) \rightarrow \R$.

   The goal is to find a perfect matching $M$ such that the weight of the
   matching which is the sum $\sum w(e)$ is maximum.[fn:27]

   In general, we say that the weighted cover $W$ is $u_0, \cdots, u_n, v_1,
   \cdot, v_n$ such that $u_i+v_j \ge w_{ij}$ for all $i, j = 1, \cdots, n$. The
   cost of $(u, v)$, $c(u, v) = \sum u_i + \sum v_j$. (*The minimum weighted
   cover problem* is to find a cover of minimum weight.)

   The interesting part is that these two problems can be solved together.
** Duality lemma
   For all perfect matching $M$ and cover $(u, v)$ in a weighted bipartite graph
   $G$, $C(u, v) \ge w(M)$ (*Home work*)

*** Corollary
    If $C(u, v) = w(M)$, then $(u, v)$ is a min-cost cover and $M$ is a maximum
    weight matching.
** Algorithm for Maximal weighted matching
   Equality: Subgraph $G_{u, v} \subset K_{n, n}$, a spanning subgraph which has
   the same vertex set and the edges at those $x$ and $y$ where $w_{i, j} =
   u_i+u_j$.
** Hungarian algorithm
   Input: A matrix $w_{i, j}$ of weights of the edges of $K_{n, n}$ with points
   $X = \{x_1, \cdots, x_n\}$, $Y=\{y_1, \cdots, y_n\}$.
   
   Idea: Iteratively adjust a cover $(u, v)$ until $G_{u, v}$ has a perfect
   matching.

   if $G_{u, v}$ has a perfect matching, then $(u, v)$ and $M$ are both optimal.
   Initial $u_i = \max \{W_{i, j}\colon j=\{1, \cdots, n\}\}$ and $v_i =0$. Note
   that this is a cover and $u_i + v_j \ge w_{i, j}$ for all $i, j$. 

   Iteration: Create $G_{u, v}$, using APA and find a maximal matching $M$ and a
   minimum vertex cover $Q$ and $Q$ will be equal to $T \cup R$ (where $T = Y
   \cap Q$ and $R = X \cup Q$)

   If $M$ is a perfect matching, then we are done. (By corollary of the duality
   lemma.)

   Else $\varepsilon = \min\{u_i + v_i -w_{i, j}\colon x_i \in X \setminus R,
   y_j \colon Y\setminus T\}$ (all elements are positive here.)

   We update as follows: $u_i = u_i - \varepsilon$ if $x \in X \setminus R$ and
   $V_j = v_j+\varepsilon$ if $y \in T$. Now you iterate.

   Why is the update $(u, v)$ still a cover? It involves 4 cases depending of
   where the pair $(i, j)$ goes to.

   1. If $x_i \in R$ and $y_j \in Y \setmius T$.
      $u_i, v_j$ are unchanged.
   2. $x_i \in R, y_j \in T$ implies that $u_i + v_j$ grew by $\varepsilon$ which
      is okay.
   3. $x_i \in X \setminus R$, $y_j \in T$, $u_i - \varepsilon, v_j +
      \varepsilon = u_i + v_j$
   4. x_i \in X \setminus R, y_j \in Y \setminus T$. So $u_i + v_j \ge w_{i,
      j}$.
* Lecture 8 <2018-11-06 Tue> 
  *Input*: $(w_{i, j})_{i, j =1}^n$ weights or $E(K_{n, n})$, $X = \{x, \cdots,
   y_n\}$, $Y = \{y, \cdots, y_n\}$

   *Initialization*: $u_i = \max_{w_{i, j}, j\cdots n\}$, $v_j = 0$

   *Iteration*: For $m$, $G_{u, v}$, $V(G_{u, v} = V(K_{n, n}), E(G_{u, v}) =
    \{x_iy_j \colon w_ij = u_i + v_j\}$
    
    Find a maximal matching $M \subset G_{u, v}$ and min vertex case $Q = T \cup
    R$.

    If $M$ is perfect matching, then return (as max weighted is perfect
    matching.), $R = X \cap Q, T = Y \cap Q$. $(u, v)$ as a minimum cost cover.

    Else $\epsilon = \min\{u_i + v_j - w_{ij}\colon x_i \in X \setminus R, y_j
    \in Y \setminus T \}$ Update $u_i = u_i - \epsilon$ if $x_i \in X \setminus
    R$ and $v_j = v_j + \epsilon$ if $y_j \in T$.

    *Remark*: $G$ is bipartite, define $w_{i, j} \iff w_{i, j} = 1 \iff x_iy_j
     \in E(G)$ vertex cover $G$ implies $u, v$ characteristic $(011)$ vectors of
     $C$, implies cover of $w_{ij}$, $w_{i, j} \le u_i + v_j$. True since if
     $w_{i, j} = 1$ then $x_iy_j \in E(G)$, then $x_i$ or $y_j \in C$, then
     $u_i$ or $v_j =1$.
     
   | x | 0 | 0 | 0 | 0 | 0 |
   |---+---+---+---+---+---|
   | 5 | 1 | 2 | 3 | 4 | 5 |
   | 8 | 6 | 7 | 8 | 7 | 2 |
   | 5 | 1 | 3 | 4 | 4 | 5 |
   | 8 | 3 | 6 | 2 | 8 | 7 |
   | 5 | 4 | 1 | 3 | 5 | 4 |

   Excess matrix
   | x | 0 | 0 | 0 | 0 | 0 |
   | 5 | 4 | 3 | 2 | 1 | 0 |
   | 8 | 2 | 1 | 0 | 1 | 6 |
   | 5 | 4 | 2 | 1 | 1 | 0 |
   | 8 | 5 | 2 | 6 | 0 | 1 |
   | 5 | 1 | 4 | 2 | 0 | 1 |

   Now we form the graph with $0$ edges and find a perfect matching.

   | x | 0 | 0 | 1 | 1 | 1 |
   |---+---+---+---+---+---|
   | 4 | 3 | 2 | 2 | 1 | 0 |
   | 7 | 1 | 0 | 0 | 1 | 6 |
   | 4 | 3 | 1 | 1 | 1 | 0 |
   | 7 | 4 | 1 | 6 | 0 | 1 |
   | 4 | 0 | 3 | 2 | 0 | 1 |

   | x |  1 |  0 |  1 |  2 |  2 |
   |---+----+----+----+----+----|
   | 3 |  3 |  1 |  1 |  1 | 0* |
   | 7 |  2 | 0* |  0 |  2 |  7 |
   | 3 |  3 |  0 | 0* |  1 |  0 |
   | 6 |  4 |  0 |  5 | 0* |  1 |
   | 3 | 0* |  2 |  1 |  0 |  1 |

   Now we end up with a perfect matching in the equality subgraph. (The ones
   labelled *)

   | x |  0 |  0 |  0 |  0 |  0 |
   |---+----+----+----+----+----|
   |   |  1 |  2 |  3 |  4 | 5* |
   |   |  6 | 7* |  8 |  7 |  2 |
   |   |  1 |  3 | 4* |  4 |  5 |
   |   |  3 |  6 |  2 | 8* |  7 |
   |   | 4* |  1 |  3 |  5 |  4 |

   The above table represents the cover in the original graph.

   Perfect matching of weight $5 + 7 + 8 + 4= 28$ and $C(u, v) = 3 + 7 + 3 + 6 +
   3+ 1 + 1 + 2 + 2 = 28$.
** Proof
   If we add edges at every step in the graph from which we get the matching, we
   would be done. But we are not exactly doing it.

   Observations: $\vert Q \vert = \vert M \vert$, no $M$-edge is covered twice by $Q$.

   $T = \{y \in Y \colon \exists M$ alternating $(U, y)$ path $\}$.

   $R = \{x \in X \colon \nexists M$ alternating $(U, Y)$ path $\}$.

   where $U = \{x \in X \colon x$ is $M$-unsaturated $\}$.

   For termination of the Hungarian algorithm, count for *the number of vertices
   that are reached from $U$ on an $M$-alternating path*. This quantity grows in
   each iteration. (or $M$-augmenting path, which implies that there is a larger
   matching.)

   The edges of $M$-alternating path starting at $U$ remain in $G_{u, v}$. Edges
   can be lost only between $T$ and $R$. But these edges are not participating
   in the alternating path. In $M$-alternating path, vertices of $T$ are only
   connected to vertices in $S = X - R$.

   By the choice of $\varepsilon$, there is at least one pair $x_i y_j$ such
   that $x_i \in X \setminus R$, $y_j \in T$,such that $x_i y_j$ is a new edge
   in the equality sub-graph.

   This means that after $\le \frac{n}{2}$ iterations, or $M$ unsaturated $y\in
   Y$ is reached via a $M$-alternating path, which means that the matching is
   growing, and the matching can grow at most $n/2$. Thus after $\frac{n^2}{4}$
   iterations.
** Connectivity problem
*** Definition (Vertex cut)
    A vertex cut of a graph $G$ is a set of vertices such that $G-S$ is
    disconnected.[fn:28]
*** Definition (Connectivity of G)
    Connectivity of $G$, denoted by $\kappa$, is the minimum size of the vertex
    cut. If your graph is disconnected to begin with, then this is zero.

    By definition, for a clique, $K(K_n) = n-1$. The empty graph is "considered"
    to be disconnected.
*** Examples
    $K(K_{n, m})= \min{n, m\}$. Proof: $\le$, Given a vertex cut of size
    $\min\{m, n\}$, smaller side

    $\ge$ Now we remove $\{m, n\} - 1$, vertices of $S$, $K_\{n, m\} - S$, and
    through them everybody else can be reached.
*** Proposition
    For all $G$, $K(G) \le n-1$. The clique is $K(G) = n-1 \iff G = K_n$.

    $K(G) \le \delta(G)$, here $\delta$ is the min degree. This is kinda clear,
    because we can pick a vertex with the minimum degree and remove all it's
    neighbours.

    $K(Q_d)$, the one skeleton of the $d$ dimensional cube.

    $E(Q_d) = \{uv \colon}$ $u$ and $v$ differ in exactly one coordinate $\}$.
    From the proposition, the minimum degree is $d$.

    I didn't write the rest of the argument. But doesn't look so hard. The proof
    was by induction.
* Tutorial
  [[http://discretemath.imp.fu-berlin.de/DMII-2018-19/][link]]
** Tutorial 1
*** Problem 2
    Each step reduces the number of components by at most $4$. After $5$ steps, at least $5$ components are left. 
** Tutorial 2
*** SAT
**** Example of un-satisfiable instance of SAT
     $f(x_1) = x_1 \wedge \neg x_1$
     
     No matter what the instance is, this will evaluate to zero. 
**** About $2^k$ clauses
     We start by proving that the statement is true for exactly $k$ variables. 

     Now we induct on the number of variables, starting from $n$. If it is true
     for $m$, then it is also true for $m+1$ because we can replace the $m+1$th
     variable by $x_1$ and bang.
**** Bound being strict
     For $k$ literals, and for $2^k$, we take all possible combinations of $x_1,
     \cdots, x_k$ such that no two literals are the same. This is not
     satisfiable. (This should evaluate to $1$ all the time.) Because no matter
     what is the value of $x_1, \cdots, x_k$, there is a literal where the or is
     zero and that literal is present in it.
*** Problem 1 bipartite
    We do a BFS. We have an array and it would be the distance. Now the claim is
    that $A(u) = A(v) \mod 2$ and if there is an edge that connects these two
    vertices, then the graph is not bipartite.

    We did prove that for BFS, the distances from the root are preserved.

    The proof was a bit complex. But it turned out to be something about
    applying BFS.
*** Problem 3 Greedy algorithm can fail
**** part a
     Algorithm: Sort the edges according to the weight in ascending order. $E =
     \emptyset$. 
     1. No vertex of degree $3$ 
     2. No cycle of length $<$ n. 

     #+BEGIN_SRC artist
                                     1
                            +-------------------+
                            | \-             -/ |
                            |   \- 2     2 -/   |
                            |     \-    --/     |
                            |       \--/        |1
                            |1      -/ \-       |
                            |    --/     \-     |
                            |  -/          \-   |
                            |-/     1        \- |
                           -/------------------\+
     #+END_SRC

     Another algorithm: start with an edge, something like a lightest edge. It's
     vague.

     
**** part b
*** TODO Problem 2
    The first $m$ edges are the smallest weight forest.

    Induction: First edge is true. Assume it's true for $m-1$ edges are minimal
    weight forest. Now kruskal adds an edge (it is the edge with smallest
    weight). It does not make a cycle. We still have a forest. Now, the weight
    the new is smaller than or equal to every other $e_i$. 

    Apparently it doesn't work.

    But we can do the induction backwards. Suppose that it is true for $n-1$
    upwards.

    $K_{m+1}$ is the forest that it construct in $m+1$ steps. (This doesn't work
    either.)

    Apparently, we could just repeat the proof for the Kruskal.

    The problem is that there could be an edge that we didn't add because it
    created a cycle before. This edge can create problems later.
**** TODO Go again through the argument of Kruskal
*** Exercise 4
**** Counter example
     Apparently any algorithm would fail on it because the shortest path does
     not make any sense.
     #+BEGIN_SRC artist
                                         x
                                         /-\
                                        /   \
                                       /     \
                                      /       -\
                                     /          \
                                  1 /            -\  1       
                                    |              \        
                                   /                -\      
                                  /                   \     
                                 /                     \    
                                /        -2             -\  
                              b---------------------------\c
     #+END_SRC
**** TODO Algorithm
     *Claim*: Right after $i$-th step of second part, $i$-th step of second
      part, $v \in V, \dist(v) \le \min \{ \vert w\vert \vert w \textup{
      contains } \le i \textup{ edges} \}$.

      1. For $i=1$, it is trivially true.
      2. For $i\ge 2$, $v \in V$, $w = $ shortest path $ \le i$ edges. There are
         parts of the argument that I skipped. [fn:17]

      It is not clear how the last part of the algorithm is able to detect the
      negative weighted cycle. The claim more or less does it.

      The time complexity is $O(mn)$
*** Exercise 5 (SAT)
**** Part a
     It's easy
**** Part b
     Write $f(x_1, \dots, x_m) = c_1 \wedge c_2 \cdots c_m$, $m < 2^k$.

     $c_i = \tilde{x_{i_1}} \and \tilde{x_{i_2}} \cdots$  

     for $e$ or $e_i$, define the set $D_i = \{v\colon \{T, F\}^n \vert c_i(v) =
     false\}$. $\vert D_i \vert = 2^{n-k}$, $\sum D_i = \{v \vert f(v) = F\}$.[fn:18]
** Tutorial 3
*** Problem 1
    We draw the graph, and remove the edges 2, 4, 8, 12. Now there are 6 odd
    number of components. There is a characterization about the maximal matching
    being the minimum of $\{n - o(G\setminus S) + \vert S\vert\colon \forall S
    \subset V(G)\}$. Now, this is $n-2$, which means if there is a matching with
    $n-2$, it will be maximal.

    Easy solution: Show that there is no maximal matching. The number of
    vertices is 18. There cannot be a matching on 17, because odd. Thus, the
    matching on 16 has to be the maximal matching.
**** Old solution
     #+BEGIN_SRC latex
       % To find the maximal matching, we use a corollary to Tutte's theorem which was mentioned in the lecture.

       % \begin{corollary}[Berge]
       %   If $G$ is an arbitrary graph, then it is true that $2\alpha'(G)$ is equal to the minimum: $\min \{ n - o(G\setminus S) + \vert S \vert \colon S \subset V(G) \}$. Here $n$ is the number of vertices in the graph.
       % \end{corollary}

       % \begin{proof}
       %   For the purpose of this exercise, we'll only prove a part of the corollary, i.e., if there is a subset $S$ of vertices such that $o(G\setminus G) > \vert S \vert$, then the maximal matching can have at most $n - (o(G\setminus S)-\vert S \vert) $ vertices. 

       %   Let $M$ be any matching in the graph. The odd components cannot be entirely matched within themselves, i.e., there will always be at least one vertex that is unmatched from within the component. We can match this vertex if there is an edge between the vertex and $S$. But since $o(G \setminus S) > \vert S \vert$, we can match at most $\vert S \vert$ number of vertices inside the odd-components of $G \setminus S$. Thus any matching (in particular the Maximal matching) in $G$ can match at most $n - (o(G\setminus S) - \vert S \vert)$. \footnote{We have not shown the existence of a match, but merely an upper bound.}
       % \end{proof}

       % For the above example, this evaluates to $18 - 6 + 4 = 16$. The maximal matching may connect, at most, $16$ vertices. We are done if we define a matching on $16$ vertices.

       % The following is a (maximal) matching on $16$ vertices.
       % \begin{figure}[H]
       %   \centering
       %   \includegraphics[scale=0.4]{maximalMatching.png}
       %   \caption{Matching on $16$ vertices; also maximal. Here $11$ and $7$ do not have a matching.}
       %   \label{fig:maximalMatching}
       % \end{figure}
     #+END_SRC
*** Problem 2
**** part a
     It is clear that $\vert V \vert = \sum \textup{vertices in even components
     of G\S} + \sum \textup{vertices in odd components of }G\setminus S + \vert S \vert$

     The above sum $\mod 2$ evaluates to $\vert V \vert \mod 2= o(G\setminus S) +
     \vert S \vert$. This is same as $\vert S \vert - o(G \setminus S \mod 2$.
**** part b
     The idea is something like this.

     For each $S$ such that the number of odd components in the complement of
     $S$ is greater than $S$, introduce a $K_d$, where it's the clique on $d$
     vertices. What should be the value chosen for $d$? Each value of $d$ should
     be equal to the the difference for that set $S$.

     Now this should satisfy Tutte's theorem (maybe we can do this inductively
     as well.) There is a maximal matching. We need to show that in the maximal
     matching contains no edge in the clique. Now, we can arrive at a matching
     on the original graph $G$ and things should be okay?
     
     I've omitted details in the steps. 
**** part b (alternate solution)
     Observation:
     1. For all even components, there is a matching
     2. For each vertex in the odd components, then $C_o \setminus \{v\}$ has a
        perfect matching.
     3. If $M$ is a maximal matching on $G[s]$.

     Proof
     1. Using Tutte's theorem: $S' \subset V(e)$, $\tilde S= S \cap S'$, then
        $\vert \tilde S\vert - o(G\setminus \tilde S)\ge \vert S \vert - o(G
        \setminus S)$ Now the LHS is equal to $\vert S \vert + \vert S'\vert -
        o(G\setminus S) - o(Ce\setminus S) \ge 0$, now we can infer that Tutte's
        theorem is satisfied inside the even components.
     2. $\vert S \vert + \vert S'' \vert - o(G \setminus S) - o(C_o \setminus
        S'') + 1$ (I missed some stuff here.)

*** Problem 3
**** Part a
     This is kinda similar to the proof of the theorem about $3$-regular graph
     without any cut edges having a perfect matching. 

     First notice that every three regular graph must have even number of
     vertices.

     Given $S$ and $G\setminus S$, we think about the the degrees of elements
     inside any disconnected component of $G \setminus S$. They cannot be $0$
     because then, it means that there are three cut edges. They may be $1$ and
     they maybe $2$ at most $2$ times.

     If it is $2$ exactly 0 times, there are no cut edges and we are done (the
     idea is that the sum of the degrees of each vertex have to be even, but the
     degrees are either 1 or 3, so there has to be an even number of vertices.)
     
     If it is $2$ exactly 1 times, then there can be at most $1$ odd component,
     and $\vert S\vert > 0$, now, Tutte's theorem!

     If it is $2$ exactly $2$ times, then we know that $\vert S \vert -
     o(G\setminus S)$ has to have parity same as $\vert V\vert$, but this means
     that $\vert S\vert$ is a non-zero multiple of $2$, and $o(G \setminus S)$
     is exactly equal to $2$. Now, Tutte's theorem.     
**** Part b
     The graph from the graph theory book
**** part c
     If $k$ is even, we can think about a clique on $k+1$ vertices.

     If $k$ is odd, then we can do a similar construction as $b$. 
*** Problem 4
    Induction on the number of vertices of the tree.

    For $2$ vertices. It has a unique perfect matching.

    For $n \ge 2$, $n$ has to be even. There has to be at least one vertex that
    is a leaf (Handshake lemma?) we picked a leaf because the edge must be in
    the perfect matching. We delete the vertex right next to the edge. And on
    each of the even component, we can use the induction argument? We need to
    prove that if we delete a vertex inside the even component, there has to be
    exactly one component is odd. 

    $\vert T' \vert = \vert T' \cap C \vert (\mod 2)$

    We can prove this. And apply induction hypothesis.
*** Problem 4 (Alternate proof)
    *Theorem*: In any tree there exist at most $1$ perfect matching. (the idea
     is that if there are two matching, then their symmetric difference must
     have a cycle.)
*** Problem 5
    Let $M$ be a maximal matching on $G$. Let $2\alpha$ be the number of
    vertices here. Let $2\alpha'$ be the number of vertices that gets connected
    in $2\alpha'$, we are supposed to show that $\alpha' > 1/2 \alpha$.

    Let the edges in the matching be $\{e_{i_1}, \cdots, e_{i_n}\}$. Where $i_1
    \le \cdots, i_n$. So when the algorithm is at the step $i_k$, either it gets
    added to $M_{t-1}$ or gets rejected. Let $x$ number of them get's rejected
    and $y$ number of them gets added.

    When does an edge gets rejected? If one of the vertex in $e_{i_k}$ is
    already in $M_{t}$. Let us now count the number of vertices in $M_t$ at the
    end.

    $M_t \ge x + 2y \ge x+y = (\alpha)$.

    Strictness: Consider the following graph and ordering of vertices:
    #+BEGIN_SRC artist
      o----------------o----------------o----------------o
             e2              e1                 e3       
    #+END_SRC

    The maximal matching is $\{e2, e_3\}$, whereas the algorithm generates
    $\{e_1\}$.
* Footnotes

[fn:28] In a good connected graph, you don't want a vertex set to be small.

[fn:27] Practical example: There is a company which has factories and corn
farms, the edges represent the profit the factory makes by producing corn from a
certain farm. There is more to this story. But I missed it.

[fn:26] I missed a lot of details here.

[fn:25] Apparently the problem for general graph is also in P. The algorithm for
this graph was what lead to the definition of $P$.

[fn:24] If the graph satisfies tutt's condition, then $\alpha$ should evaluate
to $n/2$.

[fn:23] What is a handshake lemma? 

[fn:22] An example of such a graph is Peterson graph.

[fn:21] What is a cut edge? A cut edge should mean that you remove an edge and
the graph gets disconnected.

[fn:20] What is regular graph? Every vertex has the same number of neighbours.

[fn:19] Is the $K_2$ here an edge?

[fn:18] A lower bound for Ramsey numbers was also proved in same way. Also you
can do a probabilistic argument.

[fn:17] Apparently Bellman-ford is an algorithm that is better than Djistra when
it comes to negative edges. But it works for digraphs and not for directed
graphs.

[fn:16] I think I missed some parts to the explanation.

[fn:15] Here $xy$ is an edge that is not already in $G$.

[fn:14] Why can we do this? We fix the number of vertices, so this it actually
makes sense.

[fn:13] [[https://en.wikipedia.org/wiki/Tutte_theorem][Tutte's theorem]]

[fn:12] My condition 

[fn:11] Here $o$ is the number of components of odd size.

[fn:10] Peterson graphs can be used to make a lot of counter examples. This was
taught in discrete math 1.

[fn:9] Here $C$ is the number of connected components in the graph.

[fn:8] Apparently there is a characterization that a graph is 2 colorable if and
only if it has no cycle.

[fn:7] I think it's about going through each edge once.

[fn:6] The belief is that this is not true. This is one of the Millennium problems.

[fn:5] Input is a graph $G$ and the question is whether there is a perfect matching. 

[fn:4] In general we don't know how to approximate the TSP, but we can do it with some extra conditions

[fn:3] "and the decision problem version ("given the costs and a number x, decide
whether there is a round-trip route cheaper than x") is NP-complete."-Wikipedia

[fn:2] Otherwise you can explore the components. 

[fn:1] MST would be city-side and the fastest possible way would be consumer side. 
